{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch-scatter torch-sparse\n",
        "!pip install torch-geometric\n",
        "!pip install torchdata\n",
        "!pip install igraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1DOjrKHtQqC",
        "outputId": "e6e2c087-2f65-4a36-e975-f2e3c755f616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "i3hh3MWuSkRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown # https://drive.google.com/file/d/1sMfFDVqWY39qR8vjDld4zoxDtdSuuoZ8/view?usp=sharing\n",
        "file_url = \"https://drive.google.com/uc?id=1sMfFDVqWY39qR8vjDld4zoxDtdSuuoZ8\"\n",
        "output_path = \"books_filtered_df_interaction2.csv\"  # Desired output file name\n",
        "gdown.download(file_url, output_path, quiet=False)\n",
        "print(\"File downloaded successfully!\")\n"
      ],
      "metadata": {
        "id": "fP4lKNm8U1i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_df = pd.read_csv(\"books_filtered_df_interaction2.csv\")"
      ],
      "metadata": {
        "id": "Vhuum54fWKnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_df.head()"
      ],
      "metadata": {
        "id": "eKS7xw2N52fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataframe\n",
        "df = book_df\n"
      ],
      "metadata": {
        "id": "568KR3D6JT8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get unique users and products\n",
        "users = df['reviewerID'].unique()\n",
        "products = df['asin'].unique()\n",
        "\n",
        "# Create mappings\n",
        "user_to_idx = {user: i for i, user in enumerate(users)}\n",
        "product_to_idx = {product: i + len(users) for i, product in enumerate(products)}\n",
        "\n",
        "# Total number of nodes\n",
        "num_nodes = len(users) + len(products)\n"
      ],
      "metadata": {
        "id": "eVixLxC5KvhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create edge list\n",
        "user_indices = torch.tensor([user_to_idx[user] for user in df['reviewerID']])\n",
        "product_indices = torch.tensor([product_to_idx[product] for product in df['asin']])\n",
        "\n",
        "# Combine user and product indices into a single edge index tensor\n",
        "edge_index = torch.stack([user_indices, product_indices], dim=0)\n",
        "\n",
        "print(\"Edge Index:\")\n",
        "print(edge_index)\n"
      ],
      "metadata": {
        "id": "n_wOWiNYKx5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding dimension\n",
        "embedding_dim = 128\n",
        "\n",
        "# Initialize random features for all nodes\n",
        "node_features = torch.randn(num_nodes, embedding_dim)\n",
        "\n",
        "print(\"Node Features Shape:\", node_features.shape)\n"
      ],
      "metadata": {
        "id": "RKtlh8s3Mc4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torch_geometric.nn import GCNConv\n",
        "\n",
        "# # Check if GPU is available and set device\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # Define the GNN model\n",
        "# class GNNModel(nn.Module):\n",
        "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "#         super(GNNModel, self).__init__()\n",
        "#         self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "#         self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         # First GCN layer\n",
        "#         x = self.conv1(x, edge_index)\n",
        "#         x = F.relu(x)\n",
        "\n",
        "#         # Second GCN layer\n",
        "#         x = self.conv2(x, edge_index)\n",
        "#         return x\n",
        "\n",
        "# # Initialize model\n",
        "# embedding_dim = 128  # Example dimension (change as needed)\n",
        "# hidden_dim = 64\n",
        "# output_dim = 32\n",
        "# model = GNNModel(embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "# # Move the model to GPU\n",
        "# model = model.to(device)\n",
        "\n",
        "# # Initialize optimizer\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# # Example training loop\n",
        "# num_epochs = 50\n",
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     # Move node features and edge_index to the GPU\n",
        "#     node_features = node_features.to(device)  # Move node features to GPU\n",
        "#     edge_index = edge_index.to(device)  # Move edge index to GPU\n",
        "\n",
        "#     # Forward pass\n",
        "#     node_embeddings = model(node_features, edge_index)\n",
        "\n",
        "#     # Define a dummy loss (replace with your clustering loss)\n",
        "#     loss = F.mse_loss(node_embeddings, node_embeddings)  # Example only\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     if epoch % 10 == 0:\n",
        "#         print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "F4xt94bNNibz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "hidden_dim = 64\n",
        "output_dim = 32\n",
        "model = GNNModel(embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "v3fU1-llMe-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Check if GPU is available and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "embedding_dim = 128  # Example dimension (change as needed)\n",
        "hidden_dim = 64\n",
        "output_dim = 32\n",
        "model = GNNModel(embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Move the model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# # Initialize optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def contrastive_loss(embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    embeddings: Tensor of node embeddings.\n",
        "    labels: Tensor of true labels (0 for same class, 1 for different class).\n",
        "    margin: Margin for positive pairs.\n",
        "    \"\"\"\n",
        "    loss = 0\n",
        "    for i in range(len(labels)):\n",
        "        for j in range(i + 1, len(labels)):\n",
        "            dist = torch.norm(embeddings[i] - embeddings[j], p=2)  # Distance between pair (i, j)\n",
        "            if labels[i] == labels[j]:  # Same class, minimize distance\n",
        "                loss += torch.max(torch.tensor(0.0, device=dist.device), margin - dist)\n",
        "            else:  # Different class, maximize distance\n",
        "                loss += dist\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Example training loop with contrastive loss\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Move node features and edge_index to GPU\n",
        "    node_features = node_features.to(device)  # Move node features to GPU\n",
        "    edge_index = edge_index.to(device)  # Move edge index to GPU\n",
        "\n",
        "    # Forward pass\n",
        "    node_embeddings = model(node_features, edge_index)\n",
        "\n",
        "    # Example labels for user clustering (this should be provided based on your data)\n",
        "    # Assume we have a label for each node that corresponds to its cluster\n",
        "    labels = torch.randint(0, 2, (node_embeddings.size(0),))  # Dummy labels: 0 or 1\n",
        "\n",
        "    # Calculate contrastive loss\n",
        "    loss = contrastive_loss(node_embeddings, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "symA9WFEMhCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Extract user embeddings\n",
        "user_embeddings = node_embeddings[:len(users)].detach().numpy()\n",
        "\n",
        "# Dynamically set n_clusters based on the number of users\n",
        "n_clusters = min(5, len(users))  # Use at most the number of users\n",
        "kmeans = KMeans(n_clusters=n_clusters)\n",
        "user_clusters = kmeans.fit_predict(user_embeddings)\n",
        "\n",
        "# Map users to their clusters\n",
        "user_cluster_mapping = {user: user_clusters[i] for i, user in enumerate(users)}\n",
        "print(\"User Cluster Mapping:\", user_cluster_mapping)\n"
      ],
      "metadata": {
        "id": "AuePHONZMkB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}