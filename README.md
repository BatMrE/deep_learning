## Project Notebooks

### 1. **Analysis.ipynb**
   - A comprehensive analysis of a dataset, exploring features, visualizations, and preprocessing steps necessary for machine learning tasks.

### 2. **CNN_Regulaization.ipynb**
   - Implementation of CNNs with regularization techniques such as L2 regularization (Ridge) and Dropout, aimed at preventing overfitting and improving generalization.

### 3. **CNN_Regulaization_Q3.ipynb**
   - A focused continuation of CNN regularization experiments, diving deeper into parameter tuning and testing various regularization methods.

### 4. **Pytorch_Optimizers.ipynb**
   - An exploration of various PyTorch optimizers (e.g., SGD, Adam, etc.), evaluating their performance on different models including Graph Neural Networks (GNNs).

### 5. **adaline_sigmoid.ipynb**
   - An implementation of the Adaline algorithm with a sigmoid activation function, exploring its application in linear classification.

### 6. **adni-sample.ipynb**
   - A sample analysis using the ADNI (Alzheimer's Disease Neuroimaging Initiative) dataset, performing basic data exploration and initial model development.

### 7. **mini_batch_SGD.ipynb**
   - A detailed look at mini-batch Stochastic Gradient Descent (SGD), comparing its performance to full-batch and online SGD in training neural networks.

### 8. **mini_batch_SGD_Regulaization.ipynb**
   - Further exploration of mini-batch SGD with the inclusion of regularization techniques like L2 and Dropout to prevent overfitting.

### 9. **neuron_simulation.ipynb**
   - A simulation of a simple artificial neuron, demonstrating the behavior of different activation functions and their impact on learning.

### 10. **synthetic_dataset.csv**
   - A synthetic dataset used throughout various notebooks for testing and demonstration purposes.
