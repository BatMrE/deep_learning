{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Question#1"
      ],
      "metadata": {
        "id": "uvxYBNie62lV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Dataset"
      ],
      "metadata": {
        "id": "XIpsHRWb6937"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3oQRm1uvsZV",
        "outputId": "ee27a938-edf1-408f-dd9a-67102d5f4d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# connecting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/COMP-8610/Datasets'\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1AgelnTv3xL",
        "outputId": "1f3f4115-3d2f-4cbe-88b9-44d11123aa5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/COMP-8610/Datasets\n",
            "Q1Dataset.csv  Q2Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "sTAO0OqY5HNf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.normal(0, 1, 5000) # generating 5000 instances from distribution N (0,1)\n",
        "eps = np.random.normal(0, np.sqrt(0.25), 5000) # generating 5000 instances from distribution N (0,0.25)\n",
        "y = -1 + 0.5 * x - 2 * x**2 + 0.3 * x**3 + eps"
      ],
      "metadata": {
        "id": "0xa-y5fDwHMg"
      },
      "execution_count": 613,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glrG-cA6wsQV",
        "outputId": "50e09fb6-333e-4a5d-8eb2-a323df4dbe74"
      },
      "execution_count": 614,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 614
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = [1]*5000"
      ],
      "metadata": {
        "id": "XR4x-Jfp6Ze2"
      },
      "execution_count": 615,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(x0, columns=['x0']) #bias\n",
        "data[\"x\"]=x\n",
        "data[\"x2\"]=x**2\n",
        "data[\"x3\"]=x**3\n",
        "data[\"y\"]=y"
      ],
      "metadata": {
        "id": "In9YkiT_4_rd"
      },
      "execution_count": 616,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fozCMOFw5Vv5",
        "outputId": "4b781a6b-031f-4a0d-9511-648ebed8b6eb"
      },
      "execution_count": 617,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      x0         x        x2         x3         y\n",
              "0      1  1.624345  2.638498   4.285832 -4.641451\n",
              "1      1 -0.611756  0.374246  -0.228947 -1.558609\n",
              "2      1 -0.528172  0.278965  -0.147342 -2.430615\n",
              "3      1 -1.072969  1.151262  -1.235268 -4.571957\n",
              "4      1  0.865408  0.748930   0.648130 -1.558932\n",
              "...   ..       ...       ...        ...       ...\n",
              "4995   1  1.604546  2.574569   4.131014 -4.071081\n",
              "4996   1  0.566613  0.321050   0.181911 -1.059670\n",
              "4997   1 -0.775988  0.602157  -0.467267 -3.239560\n",
              "4998   1  1.084889  1.176983   1.276896 -2.459802\n",
              "4999   1  2.241989  5.026517  11.269398 -7.270154\n",
              "\n",
              "[5000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b840446f-4b6b-4a13-9fbb-e57218018958\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x0</th>\n",
              "      <th>x</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.624345</td>\n",
              "      <td>2.638498</td>\n",
              "      <td>4.285832</td>\n",
              "      <td>-4.641451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.611756</td>\n",
              "      <td>0.374246</td>\n",
              "      <td>-0.228947</td>\n",
              "      <td>-1.558609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.528172</td>\n",
              "      <td>0.278965</td>\n",
              "      <td>-0.147342</td>\n",
              "      <td>-2.430615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.072969</td>\n",
              "      <td>1.151262</td>\n",
              "      <td>-1.235268</td>\n",
              "      <td>-4.571957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.865408</td>\n",
              "      <td>0.748930</td>\n",
              "      <td>0.648130</td>\n",
              "      <td>-1.558932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>1</td>\n",
              "      <td>1.604546</td>\n",
              "      <td>2.574569</td>\n",
              "      <td>4.131014</td>\n",
              "      <td>-4.071081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>1</td>\n",
              "      <td>0.566613</td>\n",
              "      <td>0.321050</td>\n",
              "      <td>0.181911</td>\n",
              "      <td>-1.059670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.775988</td>\n",
              "      <td>0.602157</td>\n",
              "      <td>-0.467267</td>\n",
              "      <td>-3.239560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1</td>\n",
              "      <td>1.084889</td>\n",
              "      <td>1.176983</td>\n",
              "      <td>1.276896</td>\n",
              "      <td>-2.459802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>1</td>\n",
              "      <td>2.241989</td>\n",
              "      <td>5.026517</td>\n",
              "      <td>11.269398</td>\n",
              "      <td>-7.270154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b840446f-4b6b-4a13-9fbb-e57218018958')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b840446f-4b6b-4a13-9fbb-e57218018958 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b840446f-4b6b-4a13-9fbb-e57218018958');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-327415a0-6d53-473c-b221-34162ef2ec76\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-327415a0-6d53-473c-b221-34162ef2ec76')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-327415a0-6d53-473c-b221-34162ef2ec76 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"x0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0026482589050647,\n        \"min\": -3.253034234976619,\n        \"max\": 3.9586027040379634,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.3123921151914365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.413451403048493,\n        \"min\": 5.6433468069895163e-11,\n        \"max\": 15.670535368416676,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          0.09758883363377974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.831996724033751,\n        \"min\": -34.424362112930005,\n        \"max\": 62.033423683136796,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.030485982157921653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.188010942994938,\n        \"min\": -33.786563697152374,\n        \"max\": 0.6435231715928156,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.17112505792980515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 617
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "RMu2j0DVQzlL"
      },
      "execution_count": 618,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('Q1Dataset.csv', index=False)  #storing dataset"
      ],
      "metadata": {
        "id": "caNU9AUoxrwK"
      },
      "execution_count": 619,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LApFOgiXx0aC"
      },
      "execution_count": 619,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Dataset"
      ],
      "metadata": {
        "id": "kTPRhMdOyMld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Q1Dataset.csv') #reading dataset\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kHiOtujtyO65",
        "outputId": "505dbd0c-8eaf-47b7-a916-f30718cba202"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      x0         x        x2         x3         y\n",
              "0      1  1.624345  2.638498   4.285832 -4.641451\n",
              "1      1 -0.611756  0.374246  -0.228947 -1.558609\n",
              "2      1 -0.528172  0.278965  -0.147342 -2.430615\n",
              "3      1 -1.072969  1.151262  -1.235268 -4.571957\n",
              "4      1  0.865408  0.748930   0.648130 -1.558932\n",
              "...   ..       ...       ...        ...       ...\n",
              "4995   1  1.604546  2.574569   4.131014 -4.071081\n",
              "4996   1  0.566613  0.321050   0.181911 -1.059670\n",
              "4997   1 -0.775988  0.602157  -0.467267 -3.239560\n",
              "4998   1  1.084889  1.176983   1.276896 -2.459802\n",
              "4999   1  2.241989  5.026517  11.269398 -7.270154\n",
              "\n",
              "[5000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-387768d3-d1bf-40e8-8fce-619e1c17f173\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x0</th>\n",
              "      <th>x</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.624345</td>\n",
              "      <td>2.638498</td>\n",
              "      <td>4.285832</td>\n",
              "      <td>-4.641451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.611756</td>\n",
              "      <td>0.374246</td>\n",
              "      <td>-0.228947</td>\n",
              "      <td>-1.558609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.528172</td>\n",
              "      <td>0.278965</td>\n",
              "      <td>-0.147342</td>\n",
              "      <td>-2.430615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.072969</td>\n",
              "      <td>1.151262</td>\n",
              "      <td>-1.235268</td>\n",
              "      <td>-4.571957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.865408</td>\n",
              "      <td>0.748930</td>\n",
              "      <td>0.648130</td>\n",
              "      <td>-1.558932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>1</td>\n",
              "      <td>1.604546</td>\n",
              "      <td>2.574569</td>\n",
              "      <td>4.131014</td>\n",
              "      <td>-4.071081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>1</td>\n",
              "      <td>0.566613</td>\n",
              "      <td>0.321050</td>\n",
              "      <td>0.181911</td>\n",
              "      <td>-1.059670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.775988</td>\n",
              "      <td>0.602157</td>\n",
              "      <td>-0.467267</td>\n",
              "      <td>-3.239560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1</td>\n",
              "      <td>1.084889</td>\n",
              "      <td>1.176983</td>\n",
              "      <td>1.276896</td>\n",
              "      <td>-2.459802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>1</td>\n",
              "      <td>2.241989</td>\n",
              "      <td>5.026517</td>\n",
              "      <td>11.269398</td>\n",
              "      <td>-7.270154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-387768d3-d1bf-40e8-8fce-619e1c17f173')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-387768d3-d1bf-40e8-8fce-619e1c17f173 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-387768d3-d1bf-40e8-8fce-619e1c17f173');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7966e5e7-59d5-41e4-9b7b-d84dd4807518\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7966e5e7-59d5-41e4-9b7b-d84dd4807518')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7966e5e7-59d5-41e4-9b7b-d84dd4807518 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"x0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0026482589050647,\n        \"min\": -3.253034234976619,\n        \"max\": 3.958602704037963,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.3123921151914365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.413451403048493,\n        \"min\": 5.643346806989516e-11,\n        \"max\": 15.670535368416676,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          0.0975888336337797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.831996724033751,\n        \"min\": -34.424362112930005,\n        \"max\": 62.0334236831368,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.0304859821579216\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1880109429949384,\n        \"min\": -33.786563697152374,\n        \"max\": 0.6435231715928156,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.1711250579298051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights = np.random.rand(data.shape[1]-1)\n",
        "# weights"
      ],
      "metadata": {
        "id": "UQy8uN-yyVL6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adaline Neuron"
      ],
      "metadata": {
        "id": "c29FLNION4mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BGD"
      ],
      "metadata": {
        "id": "09vdsZbCPSAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "5a4TdyXDPVZf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34sO3Y4BHBJY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaline_activation(weighted_sum):\n",
        "  return weighted_sum\n"
      ],
      "metadata": {
        "id": "DeDC9_zIPXLM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaline_bgd(data, labels, learning_rate=0.0001, epochs=5):\n",
        "  weights = np.array([0.30903487, 0.14895414, 0.71205955, 0.92752802])\n",
        "  # print(weights)\n",
        "  epoch_loss= []\n",
        "  for i in range(epochs):\n",
        "    iter_loss = []\n",
        "    delta_weight = np.zeros(weights.shape)\n",
        "    for j in range(len(data)):\n",
        "      row_j = data.iloc[j]\n",
        "      target = labels.iloc[j]\n",
        "      weighted_sum = np.dot(row_j, weights)\n",
        "      prediction = adaline_activation(weighted_sum)\n",
        "      loss = 1/2*((target-prediction)**2)\n",
        "      iter_loss.append(loss)\n",
        "      delta_weight = delta_weight + learning_rate*((target-prediction)*row_j)\n",
        "\n",
        "    weights = weights + delta_weight\n",
        "    average_loss = sum(iter_loss)/len(iter_loss)\n",
        "    epoch_loss.append(average_loss)\n",
        "    print(f\"Epoch {i+1} loss: {average_loss}\")\n",
        "\n",
        "  print(f\"Average loss of all epochs {sum(epoch_loss)/len(epoch_loss)}\", \"\\n\")\n",
        "  return weights\n",
        "\n",
        "def pred_adaline_bgd(data, weights):\n",
        "  w_sum =  np.dot(data, weights)\n",
        "  return adaline_activation(w_sum)"
      ],
      "metadata": {
        "id": "AAFP-SEmPbb9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaled_data = StandardScaler().fit_transform(data.iloc[:, :-1])\n",
        "scaled_data = pd.DataFrame(scaled_data, columns=[\"x0\", \"x\", \"x2\", \"x3\"])\n",
        "scaled_data[\"y\"]= data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "yNbrq8WfTOiV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(scaled_data , test_size=0.2, random_state=42)\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "YQ56pZxXR7jy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mse_scores = []\n",
        "\n",
        "\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(f\"****************** K-FOLD: {len(mse_scores)+1} ******************\")\n",
        "    train_data, val_data = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    train_labels, val_labels = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    weights = adaline_bgd(train_data, train_labels)\n",
        "\n",
        "    val_pred = pred_adaline_bgd(val_data, weights)\n",
        "    val_mse = mean_squared_error(val_labels, val_pred)\n",
        "    mse_scores.append(val_mse)\n",
        "\n",
        "average_loss = sum(mse_scores)/len(mse_scores)\n",
        "print(\"Average Validation Loss:\", average_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUfRh-P_Opts",
        "outputId": "1d85e30e-8cd0-4d25-93e0-34d69e90d6b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************** K-FOLD: 1 ******************\n",
            "Epoch 1 loss: 10.961310927595196\n",
            "Epoch 2 loss: 7.160221400205166\n",
            "Epoch 3 loss: 5.620793681863663\n",
            "Epoch 4 loss: 4.994327685527188\n",
            "Epoch 5 loss: 4.738985862661554\n",
            "Average loss of all epochs 6.695127911570554 \n",
            "\n",
            "****************** K-FOLD: 2 ******************\n",
            "Epoch 1 loss: 10.82031009323895\n",
            "Epoch 2 loss: 7.1438848307540965\n",
            "Epoch 3 loss: 5.633137372791974\n",
            "Epoch 4 loss: 5.01018381255373\n",
            "Epoch 5 loss: 4.753035891856867\n",
            "Average loss of all epochs 6.6721104002391245 \n",
            "\n",
            "****************** K-FOLD: 3 ******************\n",
            "Epoch 1 loss: 10.653505644200944\n",
            "Epoch 2 loss: 7.126925029563759\n",
            "Epoch 3 loss: 5.649008942273797\n",
            "Epoch 4 loss: 5.023996558632768\n",
            "Epoch 5 loss: 4.7589475365485265\n",
            "Average loss of all epochs 6.642476742243959 \n",
            "\n",
            "****************** K-FOLD: 4 ******************\n",
            "Epoch 1 loss: 10.822373611501497\n",
            "Epoch 2 loss: 7.150766976875796\n",
            "Epoch 3 loss: 5.637649547847562\n",
            "Epoch 4 loss: 5.011881185670168\n",
            "Epoch 5 loss: 4.752797243335076\n",
            "Average loss of all epochs 6.67509371304602 \n",
            "\n",
            "****************** K-FOLD: 5 ******************\n",
            "Epoch 1 loss: 11.005696698673955\n",
            "Epoch 2 loss: 7.16771852026717\n",
            "Epoch 3 loss: 5.618745074264136\n",
            "Epoch 4 loss: 4.993187492961553\n",
            "Epoch 5 loss: 4.740491685805854\n",
            "Average loss of all epochs 6.705167894394533 \n",
            "\n",
            "****************** K-FOLD: 6 ******************\n",
            "Epoch 1 loss: 10.418092085628325\n",
            "Epoch 2 loss: 7.08834790744307\n",
            "Epoch 3 loss: 5.6503311552462865\n",
            "Epoch 4 loss: 5.029288844753746\n",
            "Epoch 5 loss: 4.761075656669437\n",
            "Average loss of all epochs 6.589427129948173 \n",
            "\n",
            "****************** K-FOLD: 7 ******************\n",
            "Epoch 1 loss: 10.742234324178353\n",
            "Epoch 2 loss: 7.150255878809273\n",
            "Epoch 3 loss: 5.647981230612387\n",
            "Epoch 4 loss: 5.019670002515545\n",
            "Epoch 5 loss: 4.756873201657197\n",
            "Average loss of all epochs 6.663402927554552 \n",
            "\n",
            "****************** K-FOLD: 8 ******************\n",
            "Epoch 1 loss: 10.98901306399585\n",
            "Epoch 2 loss: 7.1615513904707475\n",
            "Epoch 3 loss: 5.6097880628917824\n",
            "Epoch 4 loss: 4.980485173595403\n",
            "Epoch 5 loss: 4.725239868690476\n",
            "Average loss of all epochs 6.693215511928853 \n",
            "\n",
            "****************** K-FOLD: 9 ******************\n",
            "Epoch 1 loss: 10.957183019352799\n",
            "Epoch 2 loss: 7.161433198414693\n",
            "Epoch 3 loss: 5.630710688157002\n",
            "Epoch 4 loss: 5.006107005122793\n",
            "Epoch 5 loss: 4.750370251401301\n",
            "Average loss of all epochs 6.701160832489718 \n",
            "\n",
            "****************** K-FOLD: 10 ******************\n",
            "Epoch 1 loss: 10.851555456806663\n",
            "Epoch 2 loss: 7.121208337979341\n",
            "Epoch 3 loss: 5.6054930209204805\n",
            "Epoch 4 loss: 4.98658248858895\n",
            "Epoch 5 loss: 4.7334503085702275\n",
            "Average loss of all epochs 6.659657922573134 \n",
            "\n",
            "Average Validation Loss: 9.315130165975011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = pred_adaline_bgd(X_test, weights)\n",
        "test_mse = mean_squared_error(y_test, test_pred)\n",
        "print(\"The mean squared error on the test dataset is:\", test_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ttpqi4ZP058",
        "outputId": "313a3ec2-7e43-4a8d-ba6f-007939fdd91d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean squared error on the test dataset is: 9.416071449422684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SGD"
      ],
      "metadata": {
        "id": "q2yYnh8bN9-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.5\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "T3tzp1CxN9Al"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaline_activation(weighted_sum):\n",
        "  return weighted_sum\n",
        "\n",
        "def update_weights(row_j, weights, learning_rate, target, prediction):\n",
        "  updated_weights = []\n",
        "  for row, weight in zip(row_j, weights):\n",
        "    updated_weights.append(weight+learning_rate*(target-prediction)*row)\n",
        "  return updated_weights"
      ],
      "metadata": {
        "id": "TwddWyGYOAdW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaline_sgd(data, labels, learning_rate=0.01, epochs=5):\n",
        "  weights = np.array([0.30903487, 0.14895414, 0.71205955, 0.92752802])\n",
        "  epoch_loss= []\n",
        "  for i in range(epochs):\n",
        "    iter_loss = []\n",
        "    for j in range(len(data)):\n",
        "      row_j = data.iloc[j]\n",
        "      target = labels.iloc[j]\n",
        "      weighted_sum = np.dot(row_j, weights)\n",
        "      prediction = adaline_activation(weighted_sum)\n",
        "      loss = 1/2*((target-prediction)**2)\n",
        "      iter_loss.append(loss)\n",
        "      weights = update_weights(row_j, weights, learning_rate, target, prediction)\n",
        "    average_loss = sum(iter_loss)/len(iter_loss)\n",
        "    epoch_loss.append(average_loss)\n",
        "    print(f\"Epoch {i+1} loss: {average_loss}\")\n",
        "\n",
        "  print(f\"Average loss of all epochs {sum(epoch_loss)/len(epoch_loss)}\",\"\\n\")\n",
        "  return weights\n",
        "\n",
        "def pred_adaline_sgd(data, weights):\n",
        "  w_sum =  np.dot(data, weights)\n",
        "  return adaline_activation(w_sum)"
      ],
      "metadata": {
        "id": "r2rAMKMLOQEy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaled_data = StandardScaler().fit_transform(data.iloc[:, :-1])\n",
        "scaled_data = pd.DataFrame(scaled_data, columns=[\"x0\", \"x\", \"x2\", \"x3\"])\n",
        "scaled_data[\"y\"]= data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "C-wkxt0-ZsW_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(scaled_data , test_size=0.2, random_state=42)\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "67ZmMlCtYEfr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mse_scores = []\n",
        "\n",
        "\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(f\"****************** K-FOLD: {len(mse_scores)+1} ******************\")\n",
        "    train_data, val_data = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    train_labels, val_labels = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    weights = adaline_sgd(train_data, train_labels)\n",
        "\n",
        "    val_pred = pred_adaline_sgd(val_data, weights)\n",
        "    val_mse = mean_squared_error(val_labels, val_pred)\n",
        "    mse_scores.append(val_mse)\n",
        "\n",
        "average_loss = sum(mse_scores)/len(mse_scores)\n",
        "print(\"Average Validation Loss:\", average_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVxIUhyYYGbD",
        "outputId": "bb359057-b5a2-4199-f1c7-855522860bfb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************** K-FOLD: 1 ******************\n",
            "Epoch 1 loss: 4.81129977518896\n",
            "Epoch 2 loss: 4.643281453166571\n",
            "Epoch 3 loss: 4.64328660207637\n",
            "Epoch 4 loss: 4.6432866051773845\n",
            "Epoch 5 loss: 4.64328660517925\n",
            "Average loss of all epochs 4.676888208157707 \n",
            "\n",
            "****************** K-FOLD: 2 ******************\n",
            "Epoch 1 loss: 4.81144002882532\n",
            "Epoch 2 loss: 4.653368653054785\n",
            "Epoch 3 loss: 4.6533698419402905\n",
            "Epoch 4 loss: 4.653369842872469\n",
            "Epoch 5 loss: 4.653369842873199\n",
            "Average loss of all epochs 4.684983641913212 \n",
            "\n",
            "****************** K-FOLD: 3 ******************\n",
            "Epoch 1 loss: 4.87924480245229\n",
            "Epoch 2 loss: 4.643557206393634\n",
            "Epoch 3 loss: 4.643561576240323\n",
            "Epoch 4 loss: 4.643561579079306\n",
            "Epoch 5 loss: 4.643561579081151\n",
            "Average loss of all epochs 4.6906973486493415 \n",
            "\n",
            "****************** K-FOLD: 4 ******************\n",
            "Epoch 1 loss: 4.817995197288009\n",
            "Epoch 2 loss: 4.654955723207427\n",
            "Epoch 3 loss: 4.654954975462554\n",
            "Epoch 4 loss: 4.654954975054717\n",
            "Epoch 5 loss: 4.654954975054512\n",
            "Average loss of all epochs 4.687563169213444 \n",
            "\n",
            "****************** K-FOLD: 5 ******************\n",
            "Epoch 1 loss: 5.186880916237384\n",
            "Epoch 2 loss: 4.6552439505059215\n",
            "Epoch 3 loss: 4.65525440133795\n",
            "Epoch 4 loss: 4.6552544070159305\n",
            "Epoch 5 loss: 4.655254407019017\n",
            "Average loss of all epochs 4.76157761642324 \n",
            "\n",
            "****************** K-FOLD: 6 ******************\n",
            "Epoch 1 loss: 4.778442262977754\n",
            "Epoch 2 loss: 4.636187821840753\n",
            "Epoch 3 loss: 4.636187194367698\n",
            "Epoch 4 loss: 4.636187193858815\n",
            "Epoch 5 loss: 4.636187193858396\n",
            "Average loss of all epochs 4.664638333380684 \n",
            "\n",
            "****************** K-FOLD: 7 ******************\n",
            "Epoch 1 loss: 4.815520910293688\n",
            "Epoch 2 loss: 4.646092699531512\n",
            "Epoch 3 loss: 4.646093479994455\n",
            "Epoch 4 loss: 4.646093480784403\n",
            "Epoch 5 loss: 4.646093480785206\n",
            "Average loss of all epochs 4.679978810277852 \n",
            "\n",
            "****************** K-FOLD: 8 ******************\n",
            "Epoch 1 loss: 4.770022563846912\n",
            "Epoch 2 loss: 4.620822555097902\n",
            "Epoch 3 loss: 4.620825350929488\n",
            "Epoch 4 loss: 4.620825351986335\n",
            "Epoch 5 loss: 4.620825351986745\n",
            "Average loss of all epochs 4.650664234769477 \n",
            "\n",
            "****************** K-FOLD: 9 ******************\n",
            "Epoch 1 loss: 4.832551363985687\n",
            "Epoch 2 loss: 4.658521097762619\n",
            "Epoch 3 loss: 4.6585207147678735\n",
            "Epoch 4 loss: 4.6585207145299385\n",
            "Epoch 5 loss: 4.658520714529789\n",
            "Average loss of all epochs 4.693326921115181 \n",
            "\n",
            "****************** K-FOLD: 10 ******************\n",
            "Epoch 1 loss: 4.816209092907742\n",
            "Epoch 2 loss: 4.640474594689817\n",
            "Epoch 3 loss: 4.64047492918316\n",
            "Epoch 4 loss: 4.640474929354315\n",
            "Epoch 5 loss: 4.640474929354403\n",
            "Average loss of all epochs 4.675621695097887 \n",
            "\n",
            "Average Validation Loss: 9.335867307612357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = pred_adaline_sgd(X_test, weights)\n",
        "test_mse = mean_squared_error(y_test, test_pred)\n",
        "print(\"The mean squared error on the test dataset is:\", test_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK3VMB3WYZQU",
        "outputId": "43f52fd4-9eca-4468-c334-72e81088b9e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean squared error on the test dataset is: 9.267542763404585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sigmoid Neuron"
      ],
      "metadata": {
        "id": "m4ebiYoN7DQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BGD"
      ],
      "metadata": {
        "id": "TYdVtI4jKFUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "O2lXxzvfE_QQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_activation(weighted_sum):\n",
        "  return 1/(1+np.exp(-weighted_sum))\n"
      ],
      "metadata": {
        "id": "GBkzahN5KMYO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_bgd(data, labels, learning_rate=0.01, epochs=5):\n",
        "  weights = np.array([0.30903487, 0.14895414, 0.71205955, 0.92752802])\n",
        "  epoch_loss= []\n",
        "  for i in range(epochs):\n",
        "    iter_loss = []\n",
        "    delta_weight = np.zeros(weights.shape)\n",
        "    for j in range(len(data)):\n",
        "      row_j = data.iloc[j]\n",
        "      target = labels.iloc[j]\n",
        "      weighted_sum = np.dot(row_j, weights)\n",
        "      prediction = sigmoid_activation(weighted_sum)\n",
        "      loss = 1/2*((target-prediction)**2)\n",
        "      iter_loss.append(loss)\n",
        "      delta_weight = delta_weight + learning_rate*(target-prediction)*row_j\n",
        "\n",
        "    weights = weights + delta_weight\n",
        "    average_loss = sum(iter_loss)/len(iter_loss)\n",
        "    epoch_loss.append(average_loss)\n",
        "    print(f\"Epoch {i+1} loss: {average_loss}\")\n",
        "\n",
        "  print(f\"Average loss of all epochs {sum(epoch_loss)/len(epoch_loss)}\",\"\\n\")\n",
        "  return weights\n",
        "\n",
        "\n",
        "def pred_sigmoid_bgd(data, weights):\n",
        "  w_sum =  np.dot(data, weights)\n",
        "  return sigmoid_activation(w_sum)"
      ],
      "metadata": {
        "id": "h-RxSx2KLEPh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data , test_size=0.2, random_state=42)\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "naWkx1BAZ6ks"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mse_scores = []\n",
        "\n",
        "\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(f\"****************** K-FOLD: {len(mse_scores)+1} ******************\")\n",
        "    train_data, val_data = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    train_labels, val_labels = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    weights = sigmoid_bgd(train_data, train_labels)\n",
        "\n",
        "    val_pred = pred_sigmoid_bgd(val_data, weights)\n",
        "    val_mse = mean_squared_error(val_labels, val_pred)\n",
        "    mse_scores.append(val_mse)\n",
        "\n",
        "average_loss = sum(mse_scores)/len(mse_scores)\n",
        "print(\"Average Validation Loss:\", average_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX26WpQJZ7wG",
        "outputId": "f2b6f03a-871d-417b-eb47-dc1768f436db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************** K-FOLD: 1 ******************\n",
            "Epoch 1 loss: 11.10442748032257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.523106412965026\n",
            "Epoch 3 loss: 9.589110245784013\n",
            "Epoch 4 loss: 9.60769880927719\n",
            "Epoch 5 loss: 9.617810093023632\n",
            "Average loss of all epochs 9.888430608274486 \n",
            "\n",
            "****************** K-FOLD: 2 ******************\n",
            "Epoch 1 loss: 11.005186473753964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.443717904174688\n",
            "Epoch 3 loss: 9.509969470854754\n",
            "Epoch 4 loss: 9.533510079383264\n",
            "Epoch 5 loss: 9.535542903614658\n",
            "Average loss of all epochs 9.805585366356265 \n",
            "\n",
            "****************** K-FOLD: 3 ******************\n",
            "Epoch 1 loss: 10.791049632012172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.156933951212627\n",
            "Epoch 3 loss: 9.222623472438267\n",
            "Epoch 4 loss: 9.247361964550512\n",
            "Epoch 5 loss: 9.258641408461491\n",
            "Average loss of all epochs 9.535322085735014 \n",
            "\n",
            "****************** K-FOLD: 4 ******************\n",
            "Epoch 1 loss: 11.020593868860871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.446037384183613\n",
            "Epoch 3 loss: 9.506912085606766\n",
            "Epoch 4 loss: 9.530997352673392\n",
            "Epoch 5 loss: 9.532055742800903\n",
            "Average loss of all epochs 9.80731928682511 \n",
            "\n",
            "****************** K-FOLD: 5 ******************\n",
            "Epoch 1 loss: 11.228544507333854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.717746971490783\n",
            "Epoch 3 loss: 9.774275792312412\n",
            "Epoch 4 loss: 9.78706116880099\n",
            "Epoch 5 loss: 9.794356428409703\n",
            "Average loss of all epochs 10.06039697366955 \n",
            "\n",
            "****************** K-FOLD: 6 ******************\n",
            "Epoch 1 loss: 10.77708061227688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.254949449513418\n",
            "Epoch 3 loss: 9.310782861315776\n",
            "Epoch 4 loss: 9.328434334065326\n",
            "Epoch 5 loss: 9.331357894683986\n",
            "Average loss of all epochs 9.600521030371079 \n",
            "\n",
            "****************** K-FOLD: 7 ******************\n",
            "Epoch 1 loss: 11.053758045724223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.544987335760007\n",
            "Epoch 3 loss: 9.604993344374762\n",
            "Epoch 4 loss: 9.621333849542554\n",
            "Epoch 5 loss: 9.623577920425467\n",
            "Average loss of all epochs 9.889730099165401 \n",
            "\n",
            "****************** K-FOLD: 8 ******************\n",
            "Epoch 1 loss: 11.28833288163907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.805594758447873\n",
            "Epoch 3 loss: 9.865739655411764\n",
            "Epoch 4 loss: 9.876517322587693\n",
            "Epoch 5 loss: 9.879104286390787\n",
            "Average loss of all epochs 10.143057780895436 \n",
            "\n",
            "****************** K-FOLD: 9 ******************\n",
            "Epoch 1 loss: 11.02182203288677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.37774106164947\n",
            "Epoch 3 loss: 9.449312297213185\n",
            "Epoch 4 loss: 9.47107316046789\n",
            "Epoch 5 loss: 9.48208543669567\n",
            "Average loss of all epochs 9.760406797782597 \n",
            "\n",
            "****************** K-FOLD: 10 ******************\n",
            "Epoch 1 loss: 11.00251971777663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 loss: 9.428088838347712\n",
            "Epoch 3 loss: 9.494288171855514\n",
            "Epoch 4 loss: 9.507286218242601\n",
            "Epoch 5 loss: 9.515818335640606\n",
            "Average loss of all epochs 9.789600256372612 \n",
            "\n",
            "Average Validation Loss: 19.133661032144722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = pred_sigmoid_bgd(X_test, weights)\n",
        "test_mse = mean_squared_error(y_test, test_pred)\n",
        "print(\"The mean squared error on the test dataset is:\", test_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhcXJpP1aNna",
        "outputId": "b8a7fb3f-8fb9-4cbb-890b-56a0eb2277a2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean squared error on the test dataset is: 21.173416793540586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-e561a5078ab6>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXx14vpJMQLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SGD"
      ],
      "metadata": {
        "id": "IKIjl_3H7KZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bias=1\n",
        "learning_rate = 0.5\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "Qg_K-G1J494q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_activation(weighted_sum):\n",
        "  return 1/(1+np.exp(-weighted_sum))\n",
        "\n",
        "def update_weights(row_j, weights, learning_rate, target, prediction):\n",
        "  updated_weights = []\n",
        "  for row, weight in zip(row_j, weights):\n",
        "    updated_weights.append(weight+learning_rate*(target-prediction)*row)\n",
        "  return updated_weights"
      ],
      "metadata": {
        "id": "W_xECiouBlqp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_sgd(data, labels, learning_rate=0.5, epochs=5):\n",
        "  weights = np.array([0.30903487, 0.14895414, 0.71205955, 0.92752802])\n",
        "  epoch_loss= []\n",
        "  for i in range(epochs):\n",
        "    iter_loss = []\n",
        "    for j in range(len(data)):\n",
        "      row_j = data.iloc[j]\n",
        "      target = labels.iloc[j]\n",
        "      weighted_sum = np.dot(row_j, weights)\n",
        "      prediction = sigmoid_activation(weighted_sum)\n",
        "      loss = 1/2*((target-prediction)**2)\n",
        "      iter_loss.append(loss)\n",
        "      weights = update_weights(row_j, weights, learning_rate, target, prediction)\n",
        "    average_loss = sum(iter_loss)/len(iter_loss)\n",
        "    epoch_loss.append(average_loss)\n",
        "    print(f\"Epoch {i+1} loss: {average_loss}\")\n",
        "\n",
        "  print(f\"Average loss of all epochs {sum(epoch_loss)/len(epoch_loss)}\",\"\\n\")\n",
        "  return weights\n",
        "\n",
        "def pred_sigmoid_sgd(data, weights):\n",
        "  w_sum =  np.dot(data, weights)\n",
        "  return sigmoid_activation(w_sum)\n"
      ],
      "metadata": {
        "id": "V30p6gZX73Gw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data , test_size=0.2, random_state=42)\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "EbA-wkkiazlh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mse_scores = []\n",
        "\n",
        "\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(f\"****************** K-FOLD: {len(mse_scores)+1} ******************\")\n",
        "    train_data, val_data = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    train_labels, val_labels = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    weights = sigmoid_sgd(train_data, train_labels)\n",
        "\n",
        "    val_pred = pred_sigmoid_sgd(val_data, weights)\n",
        "    val_mse = mean_squared_error(val_labels, val_pred)\n",
        "    mse_scores.append(val_mse)\n",
        "\n",
        "average_loss = sum(mse_scores)/len(mse_scores)\n",
        "print(\"Average Validation Loss:\", average_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6sQ9yqZazp2",
        "outputId": "e969a3dc-f3d3-4d8d-bf6d-f443642697da"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************** K-FOLD: 1 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.692733314595381\n",
            "Epoch 2 loss: 9.634698340496573\n",
            "Epoch 3 loss: 9.632394343627118\n",
            "Epoch 4 loss: 9.634209348868012\n",
            "Epoch 5 loss: 9.631345198486635\n",
            "Average loss of all epochs 9.645076109214745 \n",
            "\n",
            "****************** K-FOLD: 2 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.597808990628149\n",
            "Epoch 2 loss: 9.557660060860266\n",
            "Epoch 3 loss: 9.556574930485288\n",
            "Epoch 4 loss: 9.555115220816175\n",
            "Epoch 5 loss: 9.555115220816175\n",
            "Average loss of all epochs 9.564454884721211 \n",
            "\n",
            "****************** K-FOLD: 3 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.360201138299653\n",
            "Epoch 2 loss: 9.285284154171851\n",
            "Epoch 3 loss: 9.278755066098629\n",
            "Epoch 4 loss: 9.280843431437328\n",
            "Epoch 5 loss: 9.277772964900121\n",
            "Average loss of all epochs 9.296571350981518 \n",
            "\n",
            "****************** K-FOLD: 4 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.604996850412657\n",
            "Epoch 2 loss: 9.557001853098841\n",
            "Epoch 3 loss: 9.556030537981341\n",
            "Epoch 4 loss: 9.55297979375219\n",
            "Epoch 5 loss: 9.549971879813446\n",
            "Average loss of all epochs 9.564196183011695 \n",
            "\n",
            "****************** K-FOLD: 5 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.846039715485036\n",
            "Epoch 2 loss: 9.825680718961674\n",
            "Epoch 3 loss: 9.821545350005973\n",
            "Epoch 4 loss: 9.816978871146645\n",
            "Epoch 5 loss: 9.813996161003894\n",
            "Average loss of all epochs 9.824848163320645 \n",
            "\n",
            "****************** K-FOLD: 6 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.404173130732945\n",
            "Epoch 2 loss: 9.361584427767465\n",
            "Epoch 3 loss: 9.356330065152267\n",
            "Epoch 4 loss: 9.352143546982123\n",
            "Epoch 5 loss: 9.34794068300642\n",
            "Average loss of all epochs 9.364434370728244 \n",
            "\n",
            "****************** K-FOLD: 7 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.656312780832131\n",
            "Epoch 2 loss: 9.645989556601846\n",
            "Epoch 3 loss: 9.642421800437749\n",
            "Epoch 4 loss: 9.642226653157607\n",
            "Epoch 5 loss: 9.642226653157607\n",
            "Average loss of all epochs 9.645835488837388 \n",
            "\n",
            "****************** K-FOLD: 8 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.95217491730489\n",
            "Epoch 2 loss: 9.908502626462191\n",
            "Epoch 3 loss: 9.902660386683793\n",
            "Epoch 4 loss: 9.902760182523188\n",
            "Epoch 5 loss: 9.901481420516049\n",
            "Average loss of all epochs 9.913515906698022 \n",
            "\n",
            "****************** K-FOLD: 9 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.522508055643153\n",
            "Epoch 2 loss: 9.493298268213513\n",
            "Epoch 3 loss: 9.497434647381509\n",
            "Epoch 4 loss: 9.495802458967004\n",
            "Epoch 5 loss: 9.499357019502222\n",
            "Average loss of all epochs 9.50168008994148 \n",
            "\n",
            "****************** K-FOLD: 10 ******************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 9.567646009902209\n",
            "Epoch 2 loss: 9.53303880424067\n",
            "Epoch 3 loss: 9.533464835746429\n",
            "Epoch 4 loss: 9.530908181064632\n",
            "Epoch 5 loss: 9.529125673438804\n",
            "Average loss of all epochs 9.53883670087855 \n",
            "\n",
            "Average Validation Loss: 19.153059043231984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = pred_sigmoid_sgd(X_test, weights)\n",
        "test_mse = mean_squared_error(y_test, test_pred)\n",
        "print(\"The mean squared error on the test dataset is:\", test_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmcQMRsdazsz",
        "outputId": "b3d2cf8a-63f0-420e-fd49-f85b2cf258a1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean squared error on the test dataset is: 21.217824447813925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-6216a4e46143>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-weighted_sum))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question#2"
      ],
      "metadata": {
        "id": "aQwK7hklRTee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8Wb04z7cRXHB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Dataset"
      ],
      "metadata": {
        "id": "zaCTMHBe6am7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "X, y = datasets.make_blobs(n_samples=5000, centers=2, n_features=2, center_box=(0, 20))"
      ],
      "metadata": {
        "id": "wqfgDkmeSndT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for i, val in enumerate(y):\n",
        "  if(val==0):\n",
        "    y[i]=-1\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9m6NdyWcL3K",
        "outputId": "dd40e47d-41ce-414f-9aa1-e06f1db2a323"
      },
      "execution_count": 665,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, -1, -1, ...,  1,  1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 665
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X[:, 0][y == -1], X[:, 1][y == -1], 'g^')\n",
        "plt.plot(X[:, 0][y == 1], X[:, 1][y == 1], 'bs')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "cWwtY282b1DF",
        "outputId": "7f9e4d5f-4d7a-4fc0-9cf8-50c9d9e40109"
      },
      "execution_count": 666,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGeCAYAAAC3nVoKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpoklEQVR4nO3deXhTZdoG8DsJtEWgLWVpqbRYlKVVdhBwmcGBAdFREcdvxAUUxBkFhQ+XEQeUTaqiM8iijjPKMnzM6MwIOggFy46ytVjFKUtbCi3QAgXaUrDpkvP9EU+a5ZzknOQkOUnu33X1UtIsb9LknCfv+7zPYxAEQQARERGRjhmDPQAiIiIiTxiwEBERke4xYCEiIiLdY8BCREREuseAhYiIiHSPAQsRERHpHgMWIiIi0j0GLERERKR7DFiIiIhI95oFewBasFgsOHPmDFq3bg2DwRDs4RAREZECgiDg8uXLSE5OhtHoYQ5FUGHBggXCgAEDhFatWgnt27cX7rvvPuHIkSMO1/nxxx+FZ555RkhISBBatmwpjBkzRigvL3d7vxaLRZg1a5aQlJQkxMTECMOGDROOHTumeFylpaUCAP7whz/84Q9/+BOCP6WlpR7P9QZBUN5L6M4778RDDz2EgQMHoqGhAa+88gp++OEH5Ofno2XLlgCAp59+Gl9++SVWrFiBuLg4TJkyBUajEV9//bXs/b755pvIzMzEypUrkZaWhlmzZuHQoUPIz89HTEyMx3FVVVUhPj4epaWliI2NVfp0iIiIKIiqq6uRkpKCyspKxMXFub2uqoDF2fnz59GhQwfs2LEDP/vZz1BVVYX27dtjzZo1+PWvfw0AOHLkCNLT07Fnzx4MHjzY5T4EQUBycjKef/55vPDCCwCsAUhiYiJWrFiBhx56yOM4qqurERcXh6qqKgYsREREIULN+dunpNuqqioAQEJCAgAgNzcX9fX1GD58uO06PXr0QGpqKvbs2SN5H8XFxSgvL3e4TVxcHAYNGiR7G7PZjOrqaocfIiIiCl9eBywWiwXTpk3DrbfeiptuugkAUF5ejqioKMTHxztcNzExEeXl5ZL3I16emJio+DaZmZmIi4uz/aSkpHj7NIiIiCgEeB2wTJ48GT/88AP+8Y9/aDkeRWbMmIGqqirbT2lpacDHQERERIHjVcAyZcoUrF+/Htu2bUOnTp1slyclJaGurg6VlZUO1z979iySkpIk70u8/OzZs4pvEx0djdjYWIcfIiIiCl+qAhZBEDBlyhSsXbsWW7duRVpamsPv+/fvj+bNm2PLli22y44ePYqSkhIMGTJE8j7T0tKQlJTkcJvq6mrs27dP9jZEREQUWVQFLJMnT8bq1auxZs0atG7dGuXl5SgvL8ePP/4IwJosO3HiREyfPh3btm1Dbm4unnjiCQwZMsRhh1CPHj2wdu1aAIDBYMC0adMwf/58fPHFFzh06BDGjRuH5ORkjB49WrtnSkRERCFLVaXb999/HwAwdOhQh8uXL1+Oxx9/HADwpz/9CUajEQ888ADMZjNGjhyJ9957z+H6R48ete0wAoCXXnoJV65cwVNPPYXKykrcdtttyMrKUlSDhYiIiMKfT3VY9IJ1WIiIiEKPmvN3WPQSIiLSi5ISoKJC/vft2gGpqYEbD1G4YMBCRKSRkhKge3egtlb+OjExwNGjDFqI1PKp0i0RETWpqHAfrADW37ubgSEiaQxYiIiISPcYsBAREZHuMWAhIiIi3WPAQkRERLrHgIWIiIh0jwELERER6R4DFiIijbRrZ62z4k5MjPV6RKQOC8cREWkkNdVaFI6Vbom0x4CFiMgDNeX2U1MZkBD5AwMWIiI3WG6fSB+Yw0JE5AbL7RPpAwMWIiIi0j0GLERERKR7zGGhiKcmoTISx0NEpAcMWCii+ZpQqXVwoccETwZQyhw+zNeCyJ8YsFBEU5NQ6Xwi8kdwoXQ8u3YB6en+P0HqMYDSq0cf5WtB5E8MWIi85Euw46tHH7X+198nSLU7ZORmYsrKrP/t2FH694GamfD3bJG//t5ExICFKCD8daLUywmyrAy49VbPwY2cQMxMeDtbJJbb9/a5EZE2GLAQ+ZmSk3lUFPDZZ0BlZcCGpanKSt9O6IEIvLydERPL7e/a1TSzRUSBx4CFyM+UnMzr6oBf/Sogw3HLeSbo8GFltysu9s949CI11ZozRETBw4AljHF3B6mhZMlEzqxZ2o+HiMgeA5Ywxd0d+hEqsw9Klkz8yd1sTrgG1/xSQaQcA5YwFcwdLKFESUJlTIz1et7y9+yD84le7iTn6eQo7uQJFnf5IXoIrrV+ffilgkgdBiwU0cSESvsTeVmZY/JrfLz19+J1xIBAL7tHnE/0Uic5JSfHqCj/jE8L3gTX3ubjyN3XAw94vl50tPLgNhy/VHDGiPyJAQtFvNTUpoNoSYnnHT0xMcDWrdaT07/+BXz7rb5yOJxPciUl1h0uShJ/w4Uv+ThSKioAs9nz9f7978g9IQdixogBUWRjwEJkR+m33qFDA3uCX73aukvl8GF1W2u1PnGHCm/zcaKjrTNsX37pOMumNA9JrjBesAXiRK/0s3PokHePxSU0YsBC5IVAz0akpwP9+qm7jdKZlVAmdyJWuvwjBoKANVAZMyZw28sDlTOktxP9mDFAQYH6xwrHJTRShwELkc55k/Tra+VZPdqwwRqIxMdbZzLEAMOX4NE+EPzyS/8EolJBVVkZMHq09o8lRW8n+ro6BhXkHQYsRD8pKfEtMdNX9t/27XkzXe9r5Vk98keekP3f+9tvtb9/LZbkfN0FFsz3tBypMTH/hDxhwBKmArFdN5zoLdeDB+/A0LrUvvOJ+PBh399TWu0C0xOp1535J+QJA5YwJbVd1xlPik2CXTQNcDyI8+AdmgLRa0hq+UaL9++aNdalqo4dg3NsYP4JecKAJYzZb9el0FJba02Yvf129Z2DY2KseR4UvsrKgIMHm/6txbLPO+9YfwAGzKRPDFgorARi+2ZUVGB2CT36qHWb7b//7bhd9l//atpyKyagAk0F7+LjQ7frcyiaNw9ISwtsJ2dfk4098Wa2o127wH023GF+TPhiwEJ+E+giT4HYvrl6NdClC/CLXwRmCclsdr/Ntlkz4MMPgR49gF//OvjLWpEoLS3wnZyDHRRISU0FPvvMf9vClVaWZn5M+DKqvcHOnTtxzz33IDk5GQaDAevWrXP4vcFgkPxZuHCh7H3Onj3b5fo9evRQ/WRIP8TgoX9/+Z/u3a3X04qa7ZveSk8HhgyxHvxyc60BTDA1NAATJliXjhisBMfXX1u3XBPQs6c1OPAHMS8vN9fxR8ln0NfPPemD6hmWK1euoHfv3pgwYQLGjBnj8vsyp2pIGzduxMSJE/GAh0YcN954I7Kzs5sG1oyTP6FMb7Uf7IlTxr7M8OgtP6ixMdgjiFzvvx/sEeiHXLK/2grN7u5fT587vQu3Vgaqo4JRo0Zh1KhRsr9PSkpy+Pfnn3+OO+64A126dHE/kGbNXG5L5A/igVOLaeJgdzgm0hsGFfqgtwrHWvDrNMbZs2fx5ZdfYuXKlR6vW1BQgOTkZMTExGDIkCHIzMxEqsyraDabYbbrRFZdXa3ZmCly2M/weFO3pqTEmvxIFI6UFqxTgnWhAk/Ps9ze8mvAsnLlSrRu3Vpy6cjeoEGDsGLFCnTv3h1lZWWYM2cObr/9dvzwww9o3bq1y/UzMzMxZ84cfw2bIpDSujVA03bSw4f1mfxIpAUlBeuU8rUulLulDT1W8iX/8GvA8vHHH+ORRx5BjIcsLPslpl69emHQoEHo3LkzPv30U0ycONHl+jNmzMD06dNt/66urkZKSop2Aydd8rQe6+vyjKep7FCrJkqkJV+/jXu7VMTPHYn8FrDs2rULR48exSeffKL6tvHx8ejWrRsKCwslfx8dHY3o6Ghfh0g6oKZPiqeDVlSUtmNzpodquESRJhifu3BLVg0XfgtYPvroI/Tv3x+9e/dWfduamhoUFRXhscce88PISE+cp52bNwcWLmxafunSxbqNWMlBq67Ot8JV7g5SZWWATPxMpAvz5gFnzvh315IWO+yCQU1+TDgmq4YL1QFLTU2Nw8xHcXEx8vLykJCQYEuSra6uxj//+U+8I9Z5djJs2DDcf//9mDJlCgDghRdewD333IPOnTvjzJkzeO2112AymTB27FhvnhPpgNIiT87q64Fp0xwv++wz4OpVZbf/7DNr5Ve12yg57Uyhzh/drJ2Jn6moKOtnrWdP/Zy05bqdA+oCrHBMVg0XqgOWnJwc3HHHHbZ/i7kk48ePx4oVKwAA//jHPyAIgmzAUVRUhAq7r7KnTp3C2LFjceHCBbRv3x633XYb9u7di/bt26sdHumEVJKdt7UYfvMbayCjRGWl9SCqtPLohg3WcRUXM1ghUqquzlrRVgxc7FtHiLSYhSkpUZ5Um54O9Ovn/eOIxyom8TbR29KYQRAEIXAP5x/V1dWIi4tDVVUVYmNjgz0cknHwoLXCrb/FxABbtwaufD4RuYqKArZvty7pekPtrGdurncBi7ezq94+XqD4urQVqKUxNedvlpOlsFNba20aaD/Do1WlTSJSpq4OGDoUKCjw7oQWqGTbcE2m93UruR6XxhiwUNhixU2i4Kqr8+6EpmYpiOSF2zGQAQsREQWEkpwIQP0STTCq5LItR+AxYCEiIr9TmhPxr3+pC1ZWr7Z2Kw/0TMKYMd4vd5F3jMEeAEUOcaszEUUepTkRlZXq7jc9PThBg7jcRYHDGRYKGOcksO+/B554IrhjIiKi0MCAJUIFa3+9fRJYv37WKeItW/xT9Iq1FYiIwgcDlghUUgJ06waYzfLXiY4Gjh3z/1TrkCHWx1ISsKxeDcTHW9eO3ZXfj4qyzt787nfunyMRqde8OTB5MrB4MWCxBHcsWiTbeluVO9wpeV0CnezMgCUCHTrk+URuNluvp6eEMrGSZUGBdWxygUtdHZeaiPylvh5YtEjZdaOj/XdC0yrZVsuq3OHE1zou/sCAJQIpTWpTm/wmx9Pyk9msLpJPTbXen7dNDgNFPKg790YiihT//rf/TmhaJtuGW70SrejtdWHAQn6ldCvj1q3Wb2NyQq07LGAds9IeSEThSKrHkCfx8b4tReit/w1phwEL+ZXSrYzR0fruy+GNdeuCPQKi4BKbiwLW4D0qyv3MaEyMtXmpt0sRWvW/0WP+BjFgIR8orVrpj/sPhV0///pXsEdAFFxyyfRil2fAcek5Pt7xM692NkSr/jd6zN8gBiykgn0AUVbmebeOWLXS28fypoMqEemfeNz49a/93w3YW3rL3yAGLKSQNwGEN1UrReHaQZWIrL79Vn/dgEnfWJo/AsXHq78eAwgi0pI/ikVSeOMMSwTq2dOa5OquFktUlPW/Bw9a/+vvnBHn+w+FHBUi8j+pYwHzRyITA5YIlJpqrWIrl1BWVgY88ADwq18FbkyRXqSJiKRJHRuCmdtCwcOAJUK5Syg7eFC7kvZKaioQEanB3JbIxICF/KpjR/fbA1kCm4i0Eoz6KSxUFzgMWMjv7GdzPH24iYi8JdZPOXRIfodifDxw+rQ2QYZWhepIGQYs5DfO32RYW4Uoss2bF5jdQZ7qu3iiNMjQqlAdKcNtzaS51auB3FzXD7yet0ZPmhTsERCFt6gooG9f7e6vrEz6ci2OM2KQQfrCGRbym4oK6484y6LnrcqxscEeAVF4EwTg3DnP/YSUGj0a2LkTGDLE9/ui0MCAhTTnnEQrdmHWaueRP/zpT8EeAVF4q68HJkzQ7v4aGoChQ4GCAi63RAouCZELMdNeK2azvoMVALBYgj0CIlKrro5LN5GEMyzkQq5TaaC2ID//PPDuu9ZvUERERAADFpIhVVhOSY0DLbzzjuO/xVb0HTuybgsRUaRiwEKKSc28BCKAqKuz1lTo2NG/j0NEocm+vlMgk/uDUagukjFgIVXclfT3J86qEJGUsjLg1lu1nflVGmTILZ/bY6Vb7TBgCSEsAU1E4Wz1amsl2m3bXJeG5VRWKgtWVq8G0tOt/282N+1elKLmWBqsL3GRiAFLiGAJaCIKd/Hx1k7x/thVmJ4O9Oun/f0GU6R9iWXAEiL0WgJayRpuKNRhIaLgEkspqDlOxMRYg5xIFIlfYhmwkE+UruEC0tfhrh8iWrQIuP9+dTVVVq8Gbr89cuuw6PVLrD8xYCGfKV3DDZcPDRFp6/bbrccHNcFHerr621BoY6VbCiqtq+oSEVF44gwLBVWwarsQEVFoYcBCQee8pBSoirpEFHy+FlZj8bbIoTpg2blzJxYuXIjc3FyUlZVh7dq1GD16tO33jz/+OFauXOlwm5EjRyIrK8vt/S5btgwLFy5EeXk5evfujSVLluDmm29WOzxSQa9b4twl8nL2hSi02ddDKSuz/reiwvrjTZVaFm+LHKoDlitXrqB3796YMGECxowZI3mdO++8E8uXL7f9O9pdhR4An3zyCaZPn44PPvgAgwYNwqJFizBy5EgcPXoUHTp0UDvEsKT1twi9b4ljMSai8CTWQykp8b5CbXS047GOx4vIoDpgGTVqFEaNGuX2OtHR0UhKSlJ8n3/84x8xadIkPPHEEwCADz74AF9++SU+/vhjvPzyyy7XN5vNMNtt1q+urlb8WKFK628Ret4S527mZ9euwI6FKFyJMx3BmrVUcgwCgHnzgLS0pn/HxwM9ezJAicSlML/ksGzfvh0dOnRAmzZt8Itf/ALz589H27ZtJa9bV1eH3NxczJgxw3aZ0WjE8OHDsWfPHsnbZGZmYs6cOf4Yuq5FwreIPXuAoUOtDQ+JyH+CUfnVmxPoXXeFX4VaLUTiUpjmAcudd96JMWPGIC0tDUVFRXjllVcwatQo7NmzByaTyeX6FRUVaGxsRGJiosPliYmJOHLkiORjzJgxA9OnT7f9u7q6GikpKdo+EQq4khIGK0SBIuaLlJUBUVH++dxJzY6QdiLhS6w9zQOWhx56yPb/PXv2RK9evXD99ddj+/btGDZsmCaPER0d7TEvhkJPRQWDFaJACcQy0KxZrpeJuXFKSSXihtvMASnj923NXbp0Qbt27VBYWCgZsLRr1w4mkwlnz551uPzs2bOq8mAodMjlqHizQ4CIQouYG6eUVGAVDj1y9LpLU8/8HrCcOnUKFy5cQMeOHSV/HxUVhf79+2PLli227dEWiwVbtmzBlClT/D08CjAlu5OIiNwJ9R45et+lqVeqS/PX1NQgLy8PeXl5AIDi4mLk5eWhpKQENTU1ePHFF7F3716cOHECW7ZswX333YcbbrgBI0eOtN3HsGHDsHTpUtu/p0+fjr/85S9YuXIlDh8+jKeffhpXrlyx7Rqi8KF0ZwARUbhSs0uTmqieYcnJycEdd9xh+7eY/Dp+/Hi8//77+P7777Fy5UpUVlYiOTkZI0aMwLx58xxyToqKilBh95f4zW9+g/Pnz+PVV19FeXk5+vTpg6ysLJdEXNJOJG6JIyL/evpp4P33lV2XFa1JLdUBy9ChQyEIguzvN23a5PE+Tpw44XLZlClTuAQUQJG4JY6I/Kt7d+XXlTsGsZo1yWEvoQgWjlviTCagsTHYoyCKTGpnZMPxGET+w4CFNOcu+93XnUDNmwN//jPQu7f073ftAqZN8+0xiIhIfxiwkKa02gVk3yDNnqdlKruODUQUYPHxzI0j/2HAQprSaheQt2XDhwwBvvkGOH4c+PZb4J13fB8LUaR7/nlg8WKgvl7+OjEx1h4/vubGcUMAyWHAQrrj68FoyBDg2muBCRO0GxNRJBMD/6go4LPPAKmyWvaBiC95KZGwIYBBmXcYsISwUK6UKLfkA2gzbpb5J9JeXZ01WBFnP+2PQRUVrscjbz/L4Z6MGwlBmT8wYAlRoV4pUcmSTygHZEThqqzM+t9QPwYFW7gHZf7AgCVEKa2UuGuX40xGqJzkeTAk0qfKSut/1VRr5WeUtKC6ND+FlkcfBfr3b/rp3t0aDOgdS1dTpFm0yJojoqXnn9f2/oiCiTMsEYbfeIj06fbbgYIC+U7m3lR/jY/3eVh+x6VfUooBC2mK2e9E6omfiUjLa+DSL6nBgIU0xex3IuXEbcI9e/rnM9G6tb4bDDIPhtRgwEKa0Nu0bqA6wTZrBjQ0eHdbcWs3m71FHpMJ+Pxz/wUqotJS4I03gMuXrcmyV68C11zTtFTUurX1v2raWYTCMhOFJwYs5DM9Tuvaz/T4MyBYtw44dw44fdr678pKa/KkpwaM0dHWnAV+a4xM77wD3H13YB7HnZgYYOtWdcG9VNE4okBgwBKiAjWDoIRep3XFfAB/vlaVlcCwYU3P6+BBZe0A3nyz6f/19LekwNBLDldtrTV4PnoUOHQIGDPGfcFF+/wz5qtRoDFgCVFSuSLhtLSg5cHQU16NWAjL/puj0tfy0Ue9mz2aNg14+eWm29mPr6zMGghVVFgvf/995fdL4aldO9+WHz0Rg3u5XUr247Avv898NQokBiwhzHlHQTh949H6YOjP3Rfezh7Z305ufAcPMmAh63vj7bfV5Zp4+zhq3seRtquJgosBSxgJ9W88ekrc1csyjV7GQdryJnE1FL5oEPkTA5YwE6rfeLRM3NUi8BGDv127/LvMdviw+7FJLRcVFgIvvgjU1/tvXORf584FewT6EE6zwuR/DFhIF7RK3NUy8ElNle8orRXnYEhqbGIQWlIC3HorZ1vCwW9/65isrUQ4bicO9VlhCiwGLGFOT8ssgaDXHUtKuRubkudGoaG+Xv17sGdP644es1n+Os2bh97MW6jOClPgMWAJY4Gqj8Jp3aalnbIy/+7mIOXmzbP+d9as4I5DK6mpwLFj7r+AmM3AL36hPLAN988lhRcGLGEsULMNnNYNne3kixZZC9bZk9rWLQrlrfJpacEeQeBde630Fnl78fFNf+tw/1xSeGHAQpoItWld52RXkfMBPJi7dJyX8+TGrEa7dkC/fr7fTyiIj3c9WftL8+bA2rXWx1Ma4En9Pd0FEGpmTCPlb0yRhQELRSS5k4rzEpnc7NGuXf6tiaHk5OSN4mJrbZdI+GYdyBLya9daS+0fPKj8NlLvQXdLtEpnTHftakoWj4S/M0UOY7AHQKQn4hKZvdRU6zdW+x9/r/v7K8F21iygf39rMFRSot39ivkiehOooEWrx5F6/6n16KPWv7E//s5EwcSAhXRBXHpxJ9QTBJs3D/YImmhxYrQXifkiUtq1A6Kigj2KJlr/nYmCiUtCpAtaJe7quTJsfb31ZKakuRxPMr4J1uuYmgps3w4MHer+70xE6jFgId3QInHXXeCjhx0vn33mfvlADMqUnmhXr7bmK/jruSndsh7sombi6yCyD249jd9TEKnWkCHSTQT18P4jCmUMWMJYpNZH0fOOpY4dtd3BkZ7u3x0hSme+gj0jJPc6KBm/2tolzqQ+Q3p+DxKFKgYsYYz1Ufwn2DMKzvy5FKbk5Ks0YJk3z5rvUlwcuIJuSsbv/DlROhuyerW1rg0/Q0T+x4AlzPGbnn8EcsusEvbBqb+3XEtRGjB5E6Qozfvxhbefk/T0yOsgThQsDFgoYmi5RObvk4c3YxVPnC+95J8xuePP3CGleT/BcPiw8sf39f3n/BozJ4YiDQMWihhaLpH5++Th7VgrKpQlkEZFaZ+75K/ZPK3zfpRQGpA++qi67t++vv/sX+NIzVGjyMWAhSKKlidVf588/Lmc99lnobFUGKwTrhhc7NrlORBV049L6/cfc9QokjBgIdJAqJ089JaDA7huTQaC+5qlprqOR2+Yo0aRhAELkUZ48vCNmi3azo0hnekpOCQibaguzb9z507cc889SE5OhsFgwLp162y/q6+vx+9//3v07NkTLVu2RHJyMsaNG4czZ864vc/Zs2fDYDA4/PTo0UP1kyGi4CkpsTb/c/7Rosu08+N0797UL0fqhz10iMKP6hmWK1euoHfv3pgwYQLGjBnj8LurV6/i4MGDmDVrFnr37o1Lly5h6tSpuPfee5GTk+P2fm+88UZkZ2c3DawZJ3+IQoW/uktLUdq1WGleCRGFBtVRwahRozBq1CjJ38XFxeGrr75yuGzp0qW4+eabUVJSglQ3R49mzZohKSlJ7XCISAd87S7N3SxE5InfpzGqqqpgMBgQ76E0aEFBAZKTkxETE4MhQ4YgMzNTNsAxm80wm822f1dXV2s5ZKKQFUpbXe2TbJlzQkSe+DVgqa2txe9//3uMHTsWsbGxstcbNGgQVqxYge7du6OsrAxz5szB7bffjh9++AGtW7d2uX5mZibmzJnjz6EThaRQ2q3k7z5IWgilAJAo3PktYKmvr8f//M//QBAEvP/++26va7/E1KtXLwwaNAidO3fGp59+iokTJ7pcf8aMGZg+fbrt39XV1UhJSdFu8EQhjLuVtBNKASBRuPNLwCIGKydPnsTWrVvdzq5IiY+PR7du3VBYWCj5++joaERHR2sxVCIitxgAEumD6m3NnojBSkFBAbKzs9G2bVvV91FTU4OioiJ01GN1KyIiIgo41QFLTU0N8vLykJeXBwAoLi5GXl4eSkpKUF9fj1//+tfIycnB//3f/6GxsRHl5eUoLy9HnV2Dk2HDhmHp0qW2f7/wwgvYsWMHTpw4gW+++Qb3338/TCYTxo4d6/szJKKwIuaVuMO8EqLwo3pJKCcnB3fccYft32Iuyfjx4zF79mx88cUXAIA+ffo43G7btm0YOnQoAKCoqAgVdovCp06dwtixY3HhwgW0b98et912G/bu3Yv27durHR4RBYG/u1fbY14JUWQyCIIgBHsQvqqurkZcXByqqqpU58sQkTbEcvllZcCYMe67RivtcExE4U3N+ZvlZIlIE/bJqQUFnAEhIm0xYCEizXFnDRFpTfNdQkRERERa4wwLEemKmAsjh8tJRJGJAQsR6YaSrs9M2CWKTFwSIiLdUNL1ubbW/QwMEYUnBixERESkewxYiIiISPcYsBAREZHuMWAhIiIi3WPAQkRERLrHgIWIiIh0jwELEemG2PXZnZgY6/WIKLKwcBwR6UZqqrUoHCvdEpEzBixEpCtsnEhEUrgkRERERLrHgIWIiIh0jwELERER6R4DFiIiItI9BixERESkewxYiIiISPcYsBAREZHuMWAhIiIi3WPAQkRERLrHgIWIiIh0jwELERER6R4DFiIiItI9BixERESkewxYiIiISPcYsBAREZHuMWAhIiIi3WPAQkRERLrHgIWIiIh0jwELERER6R4DFiIiItI9BixERESkewxYiIiISPdUByw7d+7EPffcg+TkZBgMBqxbt87h94Ig4NVXX0XHjh3RokULDB8+HAUFBR7vd9myZbjuuusQExODQYMGYf/+/WqHRkRERGFKdcBy5coV9O7dG8uWLZP8/VtvvYXFixfjgw8+wL59+9CyZUuMHDkStbW1svf5ySefYPr06Xjttddw8OBB9O7dGyNHjsS5c+fUDo+IiIjCkEEQBMHrGxsMWLt2LUaPHg3AOruSnJyM559/Hi+88AIAoKqqComJiVixYgUeeughyfsZNGgQBg4ciKVLlwIALBYLUlJS8Oyzz+Lll1/2OI7q6mrExcWhqqoKsbGx3j4dIiIiCiA1529Nc1iKi4tRXl6O4cOH2y6Li4vDoEGDsGfPHsnb1NXVITc31+E2RqMRw4cPl72N2WxGdXW1ww8RERGFL00DlvLycgBAYmKiw+WJiYm23zmrqKhAY2OjqttkZmYiLi7O9pOSkqLB6ImIiEivQnKX0IwZM1BVVWX7KS0tDfaQiIiIyI80DViSkpIAAGfPnnW4/OzZs7bfOWvXrh1MJpOq20RHRyM2Ntbhh4iIiMKXpgFLWloakpKSsGXLFttl1dXV2LdvH4YMGSJ5m6ioKPTv39/hNhaLBVu2bJG9DREREUWWZmpvUFNTg8LCQtu/i4uLkZeXh4SEBKSmpmLatGmYP38+unbtirS0NMyaNQvJycm2nUQAMGzYMNx///2YMmUKAGD69OkYP348BgwYgJtvvhmLFi3ClStX8MQTT/j+DImIiCjkqQ5YcnJycMcdd9j+PX36dADA+PHjsWLFCrz00ku4cuUKnnrqKVRWVuK2225DVlYWYmJibLcpKipCRUWF7d+/+c1vcP78ebz66qsoLy9Hnz59kJWV5ZKIS0RERJHJpzosesE6LERERKEnaHVYiIiIiPyBAQsRERHpHgMWIiIi0j0GLERERKR7DFiIiIhI9xiwEBERke4xYCEiIiLdY8BCREREuseAhYiIiHSPAQsRERHpHgMWIiIi0j0GLERERKR7DFiIdCb7eDYylmUg+3h2sIdCRKQbDFiIdEQQBLyy5RUcrjiMV7a8gjBopk5EpAkGLEQ6srloMw6cOQAAOHDmADYXbQ7yiIiI9IEBC5FOCIKAWdtmwWQwAQBMBhNmbZvFWRYiIjBgIdINcXalUWgEADQKjZxlISL6CQMWksXkz8Bxnl0RcZaFiMiKAQtJYvJnYDnProi0mGVh4ElE4YABC0li8mfgiLMrRpmPoxFGr2dZGHh6FqyAjoEkkToMWMgFkz8Dq66xDiVVJbDAIvl7CyworS5FXWOd6vt2Djw7L+oc1idItUFAsAI6fz8ugyEKRwYhDM5C1dXViIuLQ1VVFWJjY4M9nJC3qXAT7vy/O10uz3okCyNvGBmEEYW/0qpSnL96Xvb3HVp2QKfYTqruUxAEDPrrIBwsO+iw1DSg4wDsn7QfBoPB6/Hqkfh8D5w5gIHJA7HvyX0en6Pze91f7/Hs49l4buNzWDxqMYZ3Ge7Xx/XmdSAKFjXnb86wkAMmfwZHSlwK+nXsJ/ujNlgB5PNicspywnKJT+0ypi8ziWpmMJxnUywWi19nMLmcS+GKAQs58GfyJwWOXOApmrl1ZkCCT2+XJrxZ2pEKAr4q+kr2frzdRq52Occ5gMjcnemX7evZx7ORvjQdz2U9x+VcCksMWMjGn8mfFFhygacoELMs3uZpeHM7ueBjyoYpkvfjy0yimhkMqUBqwe4FLp8xXwML8TU7cuEIjl04xlo+FJYYsJCNP5M/KXA8BZ4if8+yeLs04evSjsgII45dPCZ5P97OJKpZRso+no3Oizq7BFJX66+6fMZ8DSzsXzNnnGWhcMGkW3Lgj+RPCqwNBRtw79/vlZ1dseevJFPnhF+TwYR+Hft5TACVu93rv3gdU7Om2pJW7ckliduzf3wAGPTXQcg9kysZnBthRP/k/pJjVZqQLggCbv7Lzcgpy3E7LqWP6474msk9H7kxEukBk27Ja/5I/oxEwdpWKggCZm+fjUahEent0pHeLh0GSJ/8/LHEJz7vN75+w6s8DW+XdjzNJtk/vrcziWqWkTYXbVYVrLh7XE/E18xdsMLlXAoHnGGhiOe85dRXwdxW6jwDEB8Tj8raStnrJ7VKwompJxDdLNrnx7Z/3tc0vwbmBrPDLI+nWRa5bdhGgxEWoelkbD9TYG4wo/Oizjh75azH8dk//qnqU6pnEj3N5IjjUjK7YoAB6e3TsWr0KofXQu0MptLZFUDbvzWRVtScv5sFaExEuuSc4DksbZjPwYVUDkYgpuLtZwDE5ZTU2FR0bNURRyuOwgILDDCguak5/jTyTxjcaTCOVhxF3z/31SRYs3/eV+uvuvzefpZD6vWQy8OwD1bE2YwR14+AwWBAdLNoHJh0AOevnse+U/uw8JuFuLvr3Vh6YKnHx0+JS1H83OxncuSWkcRxKZldESDg4o8XcVOHm3wKINzlrgDAklFLcEvKLQCswRCDFQplXBKiiKZ1zYpgVgmWWk75/tz3OFxx2HaSFSCgrrEO7+59F30S++BPe//kVbVVcennra/fQsayDHxV9JWipRm5pQlBEDBz20yPjyu1tJQSl4K+SX2xPG85iiuL8XHex5rvdKtrrEPBxQKPy0jmBrNsAnBGuwzkTMpB7lO5eO+u99A6qjV2lexSNQ57Snb1rfpuFfom9eVyLoUFBiwUsfwRXHhb20MNqfwYQRAwc6vnE77o2MVjyNyV6VWwZj8rNWfHHByuOIwpG6Z4zKMA5PM06hrrUHixUNHjy+WM2M/uaL3TLcoUhdS4VABARvumwMP+58CkA9hxcofk7iMLLMivyEfF1QpbcFVwscCrsvzi339j4Ubu6qOIwiUhiljO0+meliw8cV6SETkvY/hCbgnLmyTPebvm2ZY45MYold8jtfRz7OIxl1wTAEhvl46/3f83lzwNcWlCvP9373wXqXGpqK6thgUWGGFEp9hOKKkucRm3899J7nXPaJeBVfevcnnNvVka2Vy0Gd+f/R4AkH/eGng4v0cEQcCYT8Z4XDYSBMHrJUP7v//s7bOx/8n9qPixQvb67p5r9vFsTPx8ImAAPrr3I03yt4j8iUm3FJHkEjyVbr+VojQp0xN3ScBSPWhGXD9C9RZaJWOUSh4G3G8J9nSf9gRBQI9lPXDswjFc2/panL582uU6BhggwPUQZb8FeHPRZtnXXYutvFJbra9PuB5GGLHkriW2v5GSBODElonoFNsJeeV5qrZ7i7TqQeScGDwgeQD2Pxl+/aVI/7itmSKa3JZi+8u1bkGgVZVg+2/QkzdMdngecktY5gaz4uUUd5yXWqTye97Y/YaipR97M7dJF6jbVLgJxy5YC7udvnxa8rWTClYAzzkjnh5bDallvmMXjuHIhSMOSzpiArCYo5IWn4b37nrPYdno7RFvI7csV3bJ0N12eC2XMJ1n5HLO6LO/FLtOkz0GLBRW5Mq6218+I3sGZm6bqWliplZVgu2DhGMXjjk8D7n8mO0ntiM1PhVGg+PzMRqMSItPw4u3vKjoOdifPKVOjjO3zsS8nfMU3Ze9ootFkjVNpmZNdbhM7rVbMmqJS76Ip5wRka8nYlsgapB+r3hKAF6et9yW9No3qS8W71ssW8fFYrG4bUmgJD9KyQleLt9Ji+BOS962dqDwxRwWCityW4rtL88py0F8TLyi4EJproP99lo5cvkE9nkcUrkYB84cwKbCTXh1+6su+RFGgxH3/uNe1FvqXZ+HYEFxZTE+P/K5bF6FM6k8C8B6cvRmyckAA1LjUhFlinK4fFPhJlvZfE/jWfXdKkweONllucJTzoho5raZXucPedo2bL+dWbx/Je9Be2LgITZFdL6d+Fw95UcBULRFXy7fSQzu9FINN1jlAUi/NM9hue6663Dy5EmXy5955hksW7bM5fIVK1bgiSeecLgsOjoatbW1ih+TOSwEyJd13ztxLwZ/NNjh8hs73IiP7/1Y9iQWqBYE9nki3RK6SZ7EjQYjbmhzg6ITvDMDDDAZTWiwNCi+jXOehRacc2N6LO2h+PnIFTxTUzTOOddDDBIf7/M4VuStcMkXEn/fKDSi4EKB7NKU8/17eg/K5f4YYECL5i1sxfacWxI81usxvLL1FbePf7D8IF7Z0nSdlNgUfHzfxw7Py1NROzGXZUvxFk2LKarlbWsHCj1qzt+aByznz59HY2PTQe6HH37AL3/5S2zbtg1Dhw51uf6KFSswdepUHD16tGlQBgMSExMVPyYDFgLkk17n3zFfssaHHnqrOI9ZaqeNr9pf0x5/uP0PeCn7JdQ31kOAAKPBiM5xnSEIAk5UnUBG+wxb1dX88/l4bO1jmj2+AQYMSB5gO9lkFWRh1JpRstdfcucS3JJ6i+3f9sGjc0JyaVUpzl05h3HrxiH/fL7sfXZr2w1HJh+BwWBwqch7tf6qQ0Xir4q+wr1/vxe1jbVoZmzmMdgTE4Bf/8XrmPjFRJRWl7pc54uHvsCk/0xSFFw5jPunIPaa5tfgx/ofZROQ+yb1xeELh10K9g3oOAD7JzUl0yrpu7Tx4Y14dfurQanULFLas4lCX1ADFmfTpk3D+vXrUVBQIPmmX7FiBaZNm4bKykqvH4MBC7nb9RPdLBq19bUO32y9/camZRl/uTF7q0e7Hlh9/2qX59P+mvYYvmq4xxkN246jv96MnDPKln+SWiZhwbAFmJY1DdV11bLXS2yZiJPTTiLKFOVxdqVbQjccmXLE5XnYBxL2J1Jzgxmpf0rFuavnZO+zubE5ql+uRkzzGLcnwxHXj1A1+2Ova5uuKLhU4HK5+F7714P/wpcFX+Ktb97CS7e8hEGdBgGwvg/GrRuHoxVHHd4HcjukpLRq3go19TWSv1PTMgAAuiZ0RcHFpucR6CDBHzv4SL90s0uorq4Oq1evxoQJE9y+wWpqatC5c2ekpKTgvvvuw3//+1+392s2m1FdXe3wQ5FH6a4fqUJianYDiY/zVdFXbpMA1e5okBuzt45UHEHF1QqXhpX/Pfdfjydgb3cclV8px6vbXsXTA592e723R7yN6GbRMDeYcbzyuNvrFlcWw9xgtv1bfF2f+PwJ1DZal4rFv1328Wz0/XNf/Py6nzvcxzMDnsGSUUts/6631GPHyR22XBDnhpBGgzUXJasgy+ulN6lgBWh6r+Wfz8fyvOU4UXnCIRm34moF8s/nu7wP7IMVI4zyBeuedP8emrnVmkwrJoZ7UlxZbEtIV7sTSYtdPVrv4KPw4dcZlk8//RQPP/wwSkpKkJycLHmdPXv2oKCgAL169UJVVRXefvtt7Ny5E//973/RqZN0DsHs2bMxZ84cl8s5wxI57Kf1ByQPAATgYNlBVdtt7Wt5yAXU7nJMPNUscRekaz27AsBWH6S23npS/+i+jyAIAu5ec7dkUq6UjQ9vxDMbnkFxZTEA62sU1SwKtQ3uc8o8LVmIr3NdYx06/bGT22Jn7Vu0R+n0UkQ3i4YgCEj9UypOXT7leJ8GI/p17AcI1iRqqdmIrm264njlcYcciLlD57pdjrq21bU4XeNaD8ZXRhhxQ8INLu+fEdePUFXXJuuRLJiMJodZvtd3vu6xrYH4Xi2tKsWKvBV4dfurtt+9dMtL6JXUCwBQfKkYs7bNkr29O1o0/fTUzFHJZ5ZCi26WhEaOHImoqCj85z//UXyb+vp6pKenY+zYsZg3T3oLpdlshtnc9A2suroaKSkpDFhCnJrlFpeuxNHxqDRXqn5MTx1sXXJM7CrD2k9PqynolX08GxM+nyCZ66Cl/kn9UWWuQuEl5SXvu7Tp4rAcoJU2MW3QoWUHLL1rKb4q+gpvffOW7HV/f+vv8cXRL7B41GLUN9bjrjV3aTaObgndUHBROolWzRKMvdTYVMmKvM6aGZtBEASHAGrn4zuR/MdkXKq95PH2RvwUpBmsO3oGJg/Engl7EPtmrGSzSXtiLgsA2WRWALZCfvaULsVoUdROSSI1u06HF10ELCdPnkSXLl3w2Wef4b777lN12wcffBDNmjXD3//+d0XXZw5L6FPz7UxqB4Hcrp/ymnJcqr2EhJgEJLZyTeR2txtIySyIw7fkslxYBAuMBiP6d5T+FigIgqIckfR26QCAwxWHEdMsxuMMhz+ZDCZ0b9cdq0avwp5Te/Dsxmc93sa+S7AgCJj4xUR8d/Y79E/qjx/O/wBzo1n2tmIibLQxGq2iW+HCjxc0ey7+YDQYAcGxjowBBjQ3/tQVO2Uwvin9RvJ12/jwRvx+y+/x/dnvba0EPv72Y7yX856ix57989mYvWO2outmPZIFALL5O4IguJ19kttptXjUYgxLG6bZrp7SqlKP5QHYyDF8qDl/+60Oy/Lly9GhQwfcfffdqm7X2NiIQ4cO4a67tPtWRfqnpuaCVA+g789+L9nfRQ3nGR5PNTjs1/ftr2cRLLLPYXPRZkUJrWKgBSCowQpgfX3zz+fj/JXzWPXdKpdaIM5MBpOtdsqW4i0Os0m55bkeH0+cLTBbzDD/KB/YBMN1sdfhTM0Z1FmaCuFJ7eoSIKDOUod3972L3w34HX67/rcu1zEZTJiaNdW2TJRfkY9zV85hxXcrFI3FCCPe+uYtRTNDRhity0YCJGu5zNw6E1XmKrf3YV/Pxrmo29yhczXry5USl4KUuBTF19cyEZ70zS8zLBaLBWlpaRg7dizeeOMNh9+NGzcO1157LTIzMwEAc+fOxeDBg3HDDTegsrISCxcuxLp165Cbm4uMjAxFj8cZltCmpuaCv3YQOM/wONducUeqD47ULIvz2I0GI3q07QEBAo5eOGqbnenRtgeaGZvhv+f/i0ah0e0J6aVbXsLQ64ai6FKRopkPX8j1+5Gz8eGNmLV9luIdR+Fq/tD5mLldPsfEfpnRX0tygHVZzt3Sk6cCfG1i2qDs+TJEN4t2Wf7pltANRZeKAr6rR4u8GQquoO8Sys7ORklJCSZMmODyu5KSEpSVldn+fenSJUyaNAnp6em46667UF1djW+++UZxsEKhT67k+Bu733DZceBpB8EbXzsGyGrHAMCh6qiShFipk7j9LIvc2C2CBfkV+Thccdj2LV287Ptz39uuJxesmAwmbDuxDSOvH4mV361U94R/khKbIlt23plcvx8pRhgxNWtqxAcrgLUrtjtikNAoNHoVrKS0TsGBJw+ga0JXAEBafBr+dv/fsHrMamx4eANyn8pFzqQcpMaluv37uQtW7CsWO7dtMBqMOHbxWFB29UjNzFL4YrdmCiq5GRMjjIhpHuNQ1Cv7eDbu/fu9MDeaZU/i1zS/BpdfvgyjUXksLjXDE90sWnbXi1L2BdMAaL4rSCRXGI8CLy46zuPSij84z+I455uoqQrsTkpsCp4e+LRDRV1P7Iv2eaJmeYfVcMND0GdYiJSSmzGxwGLLZRB76czYMgO1jbVug4ir9VfxZcGXPo1BrN3iKVjp3ra722+sAgSUVll7Emldc0VkgAELdi/Q9D7lGGFEert0xbMskajKXOVS48UbYsPHxXcuVnT9ebvmue3iLPa6sq9N443S6lLM3zlftju2lOJLjnV15KhtdqikGSSFFx55KGhsnXA9vA3F5MTcsqaEzdTYVADW3TT2J1EjjJi3c57iQlfO09v2j5nRPgNL7pQ/wB+9cNRj7YyFIxYiyhQlWaxMCwIEW90Vpdq2aIs/jvij6seywGJdvlJR6yYS+TIrBzQ1fOyT2AdL9isLMMyNZtcl1a8dl1SPVBzBi5tf9Pl9eLX+qmzgLQZaUkX7PHFe3nEevz13n1u1ndYpdDBgoaARK296OgE2Co04dvGYQ1Ai1r04XHHY4SRqgWvuiDvucmLyz+djyf4lXs8oGGDA4n2LYW4wo6SqxOcTmZTUuFS8M+IdxddffOdifPvbb/FB7geajyWSmAwmVbMMalhgQeHFQqw/tt7rBFyjwYg/bPmDbbbCYrHYKgX7430IOAZa4m4yQFkQ4RyAmAwmzN85X3a2hdVwIxNzWCionGsuiH1VjlQc8boJoFid9YuHvsAvr/+l7PU8VdX0ptOxM7GHzj//+088tq6poeCSUUvQpU0X266NNtFt8MTnT7jthyOna0JXFF4sVHQi6pbQDXm/zUPsm7E+PS/yD3FHWFp8GkwGk+Kif57M+/k8zNrhWsFWa0mtkvDMgGccKumK3BWS89SUUaqqNKvhhgdd1GEhUsK55sKmwk1uu+4qYYEFtQ21mLJhimQTPZGnGR4BAtrEtMEXD32BqGZRTZcLAh5b+xgOVxz2OJa3R7yNKFMUFu9fbKt/IdYpsT+gbjy2UXGw0v6a9g5Bnppv4ccuHsMf9/yRwYpOiUGn2BpBK3N3zfXqdlGmKHRs1VF2hjC9XTr+dv/fbO/jdi3aIf29dJfrGWHt1STWcbFnP7sitdTkfFtPn1sLLCittuaOsRpueGHAQrphn9OiRZ7EsYvHrN/cukp/cxMTEdVW1TQ3mFFWUyZziybiklBpVanbolqCIGDSfyYpfFaQHG+UMcqhmJk7SiujUvhQ2kvKWV1jHU5WnZT9/eGKww4FG1/f+bpkmwD7pVqpYoruCjQ631bp55bBSvjhkhDphlZbL+3179gfByYd0HRqWBAE9PlzHxw6e0hRhdHmpuYupejtt2BmFWThrr+zsjOFpgHJA7D/yf0QBAHXLLhGtu2C/TZ/52KKnpo/arXMw6q4+sNtzRSSxG9OuU/lIvepXOyZsAcJMQmKbisWtnKWW5areQLe5qLN+P7s97LBypJRS5AzKQcZ7TJggUXyAC7Osmwq3ITnNj2n6fgo8vhjB5pSOWdysLloM74s+NJtjygBgm2pRqQ08V5tMr0o+3i2baeR2m3TpD+cYSHVAvktRUzKNTeYcfvy293WMbHvhivSupiUIAi4+S83I6dMuoKr+E1w7tC5bhvJiZJbJeNMzRmfx0WktebG5g5LSR2u6YC2Ldri8AXH3C2TwYS+SX1RZa6SzacywID09unIeiTLpU+Q+BkXBAHj1o7D4YrDkl8GxM/W6794HU/+50lAAD667yPZY5Bz2X7nz6Q33aRJe7ro1hxIDFgCJ1i9O+R2EYhdgeW64Yq0OjiZG8xIejsJleZK2esktkxEbHSs33rCEIWqrEeyYDKaJL/wKFkSjo+Ox/UJ19tqMg3oOAD7J+2XPAa563fEqrj6wSUh8ptg9O5wVyTKvu6DXL0UcZeBXGxuP23sSZQpCqnxqbb+OwYYEGWKwrK7luG9u95DWnwaxvcez2CFyIkBBszcNhMzsmdILss4LwmLP+LyKgC0adHGoYBkTlmO5DHIpd8RHPsdsV5LaGLAQopJFXcKRFVJT0WiNhRsULzN0Zk35cC/P/u9rUaMAAF1jXVYtHcRPv72YxRXFuPdfe96+UyJwpcAAUUXi2zLqVIBQ0pcCvp17OfwU3G1AvkV1lIHUtu9Z26d6bGwnNSxgVVxQw8DFlIsGL07PJXvN8KIuTvnYv+T+23fxOwr4ma0y0DOpBwcmHRAcpujmhkj21gkuhsXXCywHYjdJR7KYX8e0kqbqDZIb5cesETcZgb31TFeuuUlbHh4g61jtC8VcKU4z7IouQ3AWZZQxKMkKRKs3h1Ki0Qltkq0fROzL9OfX5GPiqsVLrVUAPUzRmJw420FXjlGGCWDICJv3NHlDlz88aLfSvA7axDkixAaYcS2E9vQzNgM939yP747+53bLzzOy7NKm4aKsyzZx7PReVFnxY1GxeXir4q+UrwsTMHDpFtSRE3pbK05l+931qFlB1zb+lqHVvMid8l1cs9J6rmIycY5Z3L8diJo16IdJvadiE/zP0VxZTHatmiLCz9e8MtjUXj76Fcf4cXsF3Gx9mKwhwIjjLg+4XrJvC6jwYgoYxS+GPsFhncZ7pDQv3fiXgz+aLDLZ1rOxoc3Ytb2Wcg5I72DT05SyyRcG3stcstyA7qRgKy4S4g0FQq9O9QGVOJzkjoYRhmjsP7h9Q59iPxR1E5K14SuTNglnyXEJODgUwcxas0oRS0ktBBljMKk/pOw7MAy22Wpsam2RqXudEvohnfvfNdh2/H8O+Zj5raZih+/a5uuKLjk+bPTtkVbrB+73tZuI/98Ph5b29Tni9udA4sBC2lKyck6qVUSTkw94fdy2FI1YJQ0MYxuFo3ZP5+Nld+txOJRi9FoaXQb4HRN6Ipldy3D1Kyptsda/d1qhwaG/mI0GDVfdqLwEWOKQW1jrcfrzf3ZXLy607UJoT9Fm6LRYGlAo9Co+n3cNaErjl86btt2HN0sGj/W/6h4RlNc2hUfu0e7Hlg1epXLlyj7dhtSX1y6te2GI5Ple5CRthiwkOaULMtI5YloSa4GjNLZj2hTNMyNZnRr2w2xUbE4WHbQbYVNcbbDfnraUwlxIr3QqidXKDDBhEa4Lht5mi2Rm5nd+PBG2R5kpC0GLBpi7wn9cD642B+M5AIquYJyMc1iUNvg+VuqSO30NBFJMxqM6BTbCSVV7peKTAYTurfrjpX3rcT4deNtW5vlGGBwmI3xVBzO3bJwt4Rubju9k3ZYOE4j7D2hH5529EjVb+ib1Bervlslub3R3GDdepzRLgNL7lzi9rGNMGLB7gXcekykAYtgQUlVicfPU6PQiPzz+SivKVeUfO68dORp27K7HUhip3fSFx6B3QhGVVeS5k0NGHcHJPHgll+Rj8X7Frt9bAssuFp/NWKm1ym8ibWJloxyH6j7m5LPk1hnadcTuxQ3QrVngEGyVIGn+k4AMDVrKr+k6gwDFhnBqupKrrypAaO0eJQBBkU7CwDrLgiiUJdfkY/BHw3GG7vf8Pj5CDaxzlJqXCryfpfXVKq/fYai2kUCBJRWuVa5VtIluriy2DYTS/rAgEVGMKq6kjRPpfml/iZKC06pqalSZ3Et7e+NF4a8gOvir9Pkvoi80WBpwOnLpxXVNwmG9HbpyJmUg/fueg+tmrfCrpJdtmXfiqsVyD+fL7sD6ZkBzzj8e+GIhS67F8W+Re5mmeot9dhxcofvT4Y0w4BFQrCqupIrJaX5nf8mSqZ7g+nvh/6OE5Ungj0MIq+8O/JdpLdLV3WbJXcuwbK7liHKZJ2l9JQ7drjiMM5fOY/lectReKnQlkOo5Hiw4rsVtt+bDCYs3rdY8pjdKbaTT01TKfD0eUQPMm++0ZM6SjskKy3Nbz/lq2S6V8r0QdNVXd9bp2tOB+RxKPw0NzYP9hCw4rsVuPijugq6i/cvxqI9i2yf0/yKfCzZv8RtsDA1a6pLDqGS44F9vpm7Y7Y3xxYKLm5rdhIKVV1DnVw9FTne1IAprSrFv/P/jf/d/L+KxmSEER1bd8TpywwmiDz52+i/IaNDBgDr5/mxtY+pqqhrgAEmowkNFvk+RM2NzdFoaYQFFoctyqeqT0keDwRBwLi143Ck4ojDsdvd9mY91JeKdGrO3+7bbEYgNVG3v6u6hjJ39Wukdl+5K+6UEpeClLgUVY/fKbYT1vywRnG1TQssDFaIFDDAgHm75sEII5bctQS3p96OspoyVfchQECDpQGTB07GhL4TXH7vXD/JfqZk5A0jJY8Hmwo3SdZqcb6tPW+OLRQ8nGGRwKjbN+5mUJyLNXkq7uQtT72FXrr1JfRK7AXA2ndl/bH1eC/nPc0enygSiFWg+37YF4fOHlLdGPSa5tfg8suXYTQ2LQ3JFXRzd6xQ0p5jQPIAzozrEAvH+UiqCJn9D4MV99zVr1G7+0ppros9T1uajTBiW/E2PHzTw3ik5yMwGUx4P+d9xfdPRFYHzhzAlwVf4mzNWa+6mF+tv4rM3ZkOl3mTQ+hpZlyAgJKqEuajhDgGLKQpd/Vr1O6+sq80PHnDZMWBi6ctzRZYbAc+QRAwecNkrw62RJHOCCPm7ZyH/U/uxx9H/NGr+1iwewEsFmug4c2uQKBpm3LuU7l47673kBafhskDJztc5+0Rb3MZP8QxYCFNuZtB8fTNqfOizg4Bif1MzbELx2yBi/PByn4WRumWZrECZlZBFgovFWrx1Ikijhj855/Px99/+DsMUL/ccrX+KjYUbAAAbCzc6LYpqQUWFF4slJwpSYlLQd+kvlietxzFlcVYnrdc0fbmQPBmpphcMYeFNONu7blvx76AAI8dkgd0HID9k/YDgGxjMvtOqs75Mjsf34nr3r3OY+dm0Q0JN6DwovqAxbnRGlGkMhlM6JPUB6VVpTh39Zzq2xsNRvTv2N/WEf3AmQPIaJeBVfevcsh9G7d2HPIr8tE7sTe+/e23krkonnLXPHVv9ge1uyIjDXNYKCjczaDknMlB4cVCj7VRcspy3M7GAI49PpzzZXac3IF9E/cprlchFaxMHjgZnVp3QmLLRMnbMFghatIoNCK3LBfvjHgHuU/lqu5RZBGsszSZuzNtn+X8inxUXK2w5Q1WXK2w7QD67ux3knksnnLXglX4kz3ptMOAhTShZO05NT4VOZNykPtUru0nZ1IOUmNTbdczGUyYuXUmZm6bKXvgETupyuXLxEXHod5S79XzMMKI5XnLceryKdlZGqXBSlLLJK/GQBRqjDBi8f7F6JPYx231WHe3f33X6w6Xzdw6UzL3TS7w8JS7FozCn0rGzuUi5RiwkCaU1K85d+Ucbupwk8OOq/NXzqOkusR2vUahETllOcg5k+O2z8nUrKnYVLhJMl9mWc4yj+OVW2sXK2VqofxKuSb3Q6R3Yn2qmroar6pMW2DBjw0/OlwmN9sqFXgobXYa6HL7nsZuv7FAbD9A8pjDQppRW79GEAT0WNoDxy4e8+rxuiZ0xfFLxx0CGyOMaG5qDnMju6wS+dOSUUtwS8ottn+Ln2+540B5TTku1V7C8YvH8er2V5vu584leO/Aezh8wbVSbtc2XRHXIg7fln3rtiaLp9wVe0mtknBi6gm/7xhSUk9mc9Fmh3EHI8cm2NScvxmwUNBkFWRh1JpRwR4GEankbYuSr4q+wr1/vxd1ljpYBGvJ/evbXO/1l5asR7Iw4voRHovGpbdPx6rR1iTeQBX+9BREbXx4I17d/qrfi2jqHZNuSXec12kFQcDUrKlBHhXQtkVbr+tHKOXNVk8ipexzwALFvpaRM7mcDEEQMGXDFNQ21traZTQKjV4HK+LyjrnB7LFoXNnlMttydCCCFSU5fWJzR6VFNMkPAcvs2bNhMBgcfnr06OH2Nv/85z/Ro0cPxMTEoGfPntiwYYPWwyKNeFt51nmd1txgxvHK425vF4gT/ZN9n8QrW1/x62NxRxH5k30OWCCJtYzsJ+nd5WRsKtzkdXAixQILDpYdxNYTW21F45wT+jPaWRs0psalIsoUpdlje6Ikp6+4stgloAnWTqZQ4ZfmhzfeeCOys5tOaM2ayT/MN998g7FjxyIzMxO/+tWvsGbNGowePRoHDx7ETTfd5I/hkZecD0bD0oYpmrqU29bnrlPrklFLcHPyzWhmcnzvCIKAcet+6sgqWGA0GNGjXQ+svG8lHvj0AVUHbwMMWLRvEfNdiLwgQHBpBCvX2NTXGdXFdy7Gram3Nj32T8eB/PP5mL19NvY9uc+liaF9M0RxK3Sg8kPEyrtyOX3OzR1F7ho1kh9yWGbPno1169YhLy9P0fV/85vf4MqVK1i/fr3tssGDB6NPnz744IMPJG9jNpthNjedZKqrq5GSksIcFj9zXpNVkiAm1eywb1JfwAAcPCNdRM7d+rjcuvD8ofMxc/tML58ZESmV0T5DMh/kq6KvcO8/7kVdQx0ssDjkZGwq3ORTvlr/jv1xYNIB2/HA07EoUE1WveGpUaO3+UGhKug5LAUFBUhOTkaXLl3wyCOPoKRE/lvvnj17MHz4cIfLRo4ciT179sjeJjMzE3FxcbaflBS2B/c3pbUQnElt68spc19ETtwi6Vx+210vonm75il6HuJ6f3Njc3S4poOi2xBRk/zzTUXdxGDFlp/SUGv7XIuzBZsKN+HZLNfZBGeto1rL/i63LNdhK7CnY5HaJquBpGS5SOr4R36YYdm4cSNqamrQvXt3lJWVYc6cOTh9+jR++OEHtG7t+oaMiorCypUrMXbsWNtl7733HubMmYOzZ6ULd3GGJfDkZjbczbK429Z3Y4cb8fG9H8t+gzhacRTzds7D4lGLMbzLcLdjUIoVaol8ZzQYcUPCDdb+PD99PuV2/JkMJnSJ74KCSwWy97dk1BIM6TQEE7+YiENnD8meyMW2Hc5bgUXisUjJduJgz1yoLQERztTMsGiewzJqVNObtlevXhg0aBA6d+6MTz/9FBMnTtTkMaKjoxEdza6bgWL/jcb5ADBr2yyMuH6E5AHAfj3bXqPQiO/Pfo+KqxWSwY4gCPjd+t855MoAsGXdqy1KZbtfBitEPrMIFhy7YE2efWXLK/jFdb+QzU9pFBrdBitGGLHqu1V4su+TKK8pd/vZLrpUBHODWfJYZDQYbccid8cdveSHpMSluOTckGd+39YcHx+Pbt26obBQusFcUlKSy0zK2bNnkZTEsubBJu4IeuPrN9x2WXbX10Ntm3hAOnHP0zSqHAMMSItPw9yhcxXf5qVbX8ILg19Q9ThEkejAmQPI3JXp9e4fcfnDYDA47PTJmZSDjPYZMBqsxw+jwYjUuFRsP7Fd8lgk9iPaVLjJ6+MO6Z/fC8fV1NQgNTUVs2fPxnPPPefy+9/85je4evUq/vOf/9guu+WWW9CrVy/ZpFtnLBynPfsOo9c0vwa19bWqEsTMDWZ0XtTZbddkqYqT7pLlTlWfcphGFQQBj619DIcrXCtkOuuW0E1R80UjjOiX3A9nqs/gTM0Zj/dLFMmMBiNimsWobmdhXyVXavlDbvnX3efYAAP6deznsWt0oCrdkjJBXRJ64YUXcM8996Bz5844c+YMXnvtNZhMJluOyrhx43DttdciMzMTADB16lT8/Oc/xzvvvIO7774b//jHP5CTk4MPP/xQ66GRCvazHO4ORvYJYvYHAE/b+gDrgcr5oOE8nes8jWs/jWpuMKPscpnH52KAQfE3QAssKLxQiEpzpaLrE0Uyi+C+91ZqXCpKq0odlmNNBhNWfbcKkwdOllxKdrcEfbzyuNsCcaerT+PrCV+jylwlWf5g1ehVSGyVyGAlRGkesJw6dQpjx47FhQsX0L59e9x2223Yu3cv2rdvDwAoKSmB0dg0XXfLLbdgzZo1mDlzJl555RV07doV69atYw2WIHI+YBjx04f9/lWSBxipwANQv06rNlcmyhSF1PhUVJ6tdH+/CnJXDDAgvV06Vo5eiQf/+SADFiIfGWBASZXrDlFPuSTuclAgWGdnAEjWMVk4YiFuaHuDtQbL+Xzb5RbBYtvd1D+5vy9Pi4KIvYTIhTc7gvz5uHKPr2TZyWQwoVXzVqiqq1I0BtZzIZKWGpuqWVVduaVkJTVK+iX3AwTg23Lphoh7J+7F4I8G63qXEDUJeh0WCl3uap34M1nNmyRdcdnJuSS3+A0MsH4r+9PIPyGhRYLHMRhhxIKvF/j8XLomdEVKa+4AIP1rf017LL5zsaLrllSXKG5h8dv+v0WbmDayv5erNaKkRsnBsoPIKcuR3QSQuTtT9SYBCg2cYYkQ2cez8dzG5xzqmkhRO8uhFW+TdJ3JJe3+68F/4UzNGdy95m5c/PGi7O192TZNFIq6JnRF0cUiTd/31zS/Bu/f9T7Gfz7e5Xdiwq1crRG5GiVKkuwNMKBF8xaqNwlQ8Kg5fzNgiQD2O34GJg+U/bAGu2S0FsWU5AKuBcMWYMZtM1BaVYrPj34uuf4t1b9I7Fly+Pxh1nEhUuHaVtei/Eq5ZssySgtHGg1GWzdoKdwlpC8MWMiBkh5A2cez8eyGZ1F+pRyVtZWy96XnD7tchUvA+o3v8suXYTAYVFXB9LW6rhSTwYS3f/k2/nfz/2p6v0ShQu1MrfNn291GgAZLA5oZ5feTRFIV2VAQ1G3NpC/OO2+kdtyIXZiPXDiCXom9kP1Ytuy3H7kdQXogt7sAsG7NztydiQHJAxRXwRRfO61L+jcKjVj4zUJF12U7ARKZYEIjGj1fUefEfDSjwYipWVM9LlMDrp9tCyzIr8iXrZZN4YkzLGFOyY4fb7ow642n5SzAOsuS3jYd35Z/q2jJS0lejb892edJ/DXvr6pu08zQDA1Cg59GROS7xJaJ6BTbCblluW6XqQH3Pcm46yf0cZcQAVC248fbLsx6o6R0/9X6q6q6RIu7kHIm5SCjXYbsDiZ7SndRSHkw/UGkxafZ7sMAA/526G+q74fBCulF2xZtsWfiHpedfG+PeBu5ZbkA4HHnjnPnZRF3/UQeLgmFMSVNwAC4rSwbKuwr6wqCgHFrf6pyaRecGGFE5zadHbpEi0m1+efzkdE+A1mPZDkseaXEpSD/fD7yK/JdHlOKL8s3Xxz7AubGpi7kAgSHfxOpYYABux7fheGrh6O2odbj9eOj4/HyrS9jxtYZPr2PM9pl2HJLpPJFxOam7pap7a/rrumpuLwk14CVwgtnWMKUkromM7fNxMytMwNec8VfUuJScPHHi7j/k/uRX5HvcoCzwGLrEt2vYz/069gPFVcrbBUx88/nO1THBDy/jloyN5p9mqGh8DXn53McZt+UECDghjY3oK6hzu31DDBgx/gdOPTMIUwbMg1tW7T1aawXay/ipg43oV/HfpLJrc4zJu5mSpTUZZGq50LhiTksYUpJ/kWbmDa4VHtJ9vehlssiCAJu/uvNyDmTI3sd+zwVALKNFsVva0pex7Yt2mLm7TO564f8wggjuiR0QfGlYpdlEU/+89B/0L5lexReKgRg/Yy8uu1VFFcWW7uY3zEX3dt2x8BrB9puY19ewN22/kHJg6xVZwG0bN4SvRJ74cYON7rdheNNPooW5Q5Iv7itmQC4/6ALgoCJX0zEobOHwqbAktItyOLW7O0ntitqQSD1Ou47tQ8Lv1mIF295Eb/q9is88OkDktupibTQzNgMDZYGxDSLgbnBrHjJZkDyAOx/cr/tM+z8GVkwbAH+9t3fZHfquPtMiaUC7HvDeRKswpSkXwxYyCOtKsvqhUudBrvurM4BV4eWHXBt62u93nngXIhv7tC5GLVmlF+fH0WeJaOWwGQwYc6OOT7tVBODAKkq0NHNonG1/qrkTh13dY1E8++Yjz/87A+KxhHswpSkT6zDQh7ZJ6nK0XPNFWcudRrsurNKfWPbVLhJcT0Wd4914MwBTM2a6peS/jGmGJgblX+bpvCyIm8FDDA4BCv2BdPOXjmLiz9exKvbXsWJyhOS7xP7pFTnz0ij0Iir9VcBQPI9766ukWjBbmsF6a0ntnps/aEmHyVUjjsUWJxhoZCndl3cl296Ut9SDQYDGizqtxJ3bNURzwx8BgBQcKEAq75fpfo+KHy1at4KNfU1kr8TZ02UzpQWP1eMn634mexsifN7XkldI9H8ofPx+bHPPbb+AJiPQq44w0IRRcn2bftvjr5805P6lgqhqaGbqLSqFOPXjUeVuUp23AIEvHjLi4gyRWHQXwfZtnmKjDAiqlmUoi2pShkNRjQzNuOuCp1IapmECz9eQL2l3uV3cssw9tuAlc6U7ji5w+1siQUWh8+KkrpGonm75tm233uanUyJS0FKHDuZk3c4w0IhzdvZEm++6amdyVH6GP7oVxRMN7S5AVGmKBy5cMRtE7pw4GvrBF+WEpUmqCqdLXH+rJRWleL05dMeO5wDTa+DpxwwpV3jKXKw0i1FDG/rNKTEpdhqsUj9OAcr2cez0XlRZ1UVN8W6MI9+9igu/nhR8jE81XkxwICM9hlYcucSt6/DkjuXIPepXCwbtQxRxqig1nMpvFRorYMT5sEK4F2hwNZRrdGjXQ8A8DpYEXNTlHzfVDpbYj/LAljfv4M7Dca3T32LjPYZbt9T4uvgrqaK2LPscMVhvLLllZCr80TBxxkWCnn+XhcXBAE3/+Vm5JQpq+9iX0XXfjeR1LdOJTkIYt+Vb8ukeyABQLeEbjg8+TDSl6Xj2MVjXjzLyGWAAfsm7oPJZEJ5TTk+yv0Inx39zG+PlxafhuLKYp/vR80uPvEzIggCxnw6BiVVJbLX7da2G45MPqKqFpE9uVnNcOhZRtpjDgtFFH+vi28u2uw2WAGk816cdxNJre0ryUGIi47DrR/f6vYbcnFlMdYfXR9xwUpKbAoMMKCkWv4E7IkAAaeqT+H+jPthsVjw4D8f1HCErkqrS71eCjLAgPT26Vg1ehUSWyUq3k0jfkZq62tx5vIZt9c9fuk4zA1mxDSPASD/Hv2m9Bs8u/FZl9s758MAyrrGE3nCgIXIDecDrf22Uqn6LuIJRM0BWi7gsl/vPzDpAD4/+rnkCQIA6i31eP6r5zV61r4xwggYEJAlodPVpzXZTr7g6wUYnT4aGwo22Lb6+kNqXKrb2Q1PBAi4+KO19L03W393nNzhsKNNTBa3Dz4aLA3YcXKHQ3Dt/B4V+wHJBV4GGBze71LJ6qHYs4yCizksRG449z2xwIL8inyHfkTiz5GKI8hYloHs49mq+qVIcV7vv7b1tVj13Sq3uS5i+XV7Lw15yaUHjb/7IllgkQ1WTAYTUuNSNX0sLRRdLIK5wYy5O+f6Nf/ndPVpVa9/2xZtsWeCY7fjA5MOeBWsSHVmX/XdKvRJ7INV361S1bHdU16MAAElVSWoa6xT1DWeSAkGLBTWso9n24IItdQcaO0DjBlbZvjcVNJ5OenLgi89niCcGWHEon2LUFxZ7PB7rQvcqdEoNKKkqiQgzSTVEIOokqoSvxXqax3VGo1Co6LXP71dOnIm5SDvd3kYnDLYbUK4UnJBdObuTNXBtbhMlPtULpaMkk4If3vE24huFu3yuCK1QTwRk24pbClJenVHTd8TNVuTPSUbSjVxHJA8AP9+8N+o+LHC5fpyuQT+YoABneM7AwBOVp6EAAFGGNEptpNPuSTBlNgyESenncS5K+fcLr3JadW8FVaPWW0r9JYQk4DEVom234u9u74/+73igEjLpFS5LflGGBHT3NqfSG2LCnf3K95+78S9GPzRYJbjJ1lMuiWCsqRXOfbbjeUOtOIaPQCHfBV37G8nV6diwucTUFpd6nB5zpkcHK447DJ+T7kE/iBAwInKEw6XWWBBSXWJz3VJ0uLTMO+OeXBYlRGAOdvnoOBSgdf3K2rboi3WP7weOWdyHIISo8GIXSW7MCxtmG3pTenraYAB1ydcj3u73yt70jU3mFFeU+72tTEZTBAEARZYFCWlqqlpIldc0QKLZM6O0hwTT0UbNxRsYDl+0gxnWCgsSZXQV/KNUaSmOaRc12dPt3M+QEvNrNhz7ryrdJx6kRCTAAECLtVekr2O1Gvj7XMUg5MoU5TtMneNLwd0HIBdT+zCde9e59Xr6WlGxN32e7lZMrn7VDN7qKbMvj1Psx9Kizb+68F/Sc4MiliOP7JxhoUinq+7EpSWPI8yRbmdXTHBhEY0Xb5k1BKM7jFa8tvk5qLNssEKYJ1lcR6/1DgDvUTkTNx5IggCxq0dh/yKfGS0y0DWo1kAoLrh5q6SXWgd3RrRzaJxqvqUQ0KvAQZcF38dlt61FEmtklzuS+pEKNf4Mqcsx1rCXuLvLggCxq0bh8PnD3tsMigXOMjtBhNnyZzfQ+5mWdTMHqops2/P0+yH0qKNia0SkRqvXaI1RS7OsFDYUVtC3xdqclfcPb6n2RWR1CyL8/1I5ioYftqOPXoV9pzaozqgEW+/8r6VGL9uPA5XyJ+4xW/lm4s2+1wozH4mwR21ZerlmgAO6DgA+ye5vr5qZtzULm2oyZUSn0OPZT1w7IK15o6S93VpValsbs5Lt76EoZ2HOuTciDzNfrCZIfmKMywU0dQ2Q/SWpzwXNY/vaXZFVHSxyO16v2yugmBB/vl8nL9yXnWOhv3ty2vKceHHC7K5GOK3anOD2atCYc55GXLPx56S2Q2Rp/vLKXOdxQKUz7ipDVbU5EqJz21T4SZbsAIoe193iu1k27rsHMRvK96GN4a94VUQz2aGFEgMWCiseHMC8JY3U+1SJ27nInNyDDAgNS7VISfDnpLnPnPbTJRWlXqVoGuEEXN3zsX+J/c75CSIyyX55/OR0T4DWY9kuXQHVnJSda4984vrfqHodVGauKk0wJy5daaqAn++UNs5XBAETM2a6nI9TwFhoIJ4In9iwEJhRe0JwBfit+5zV85h3Npxsssk9sQTxBu738CM22cA8PytXyRAwNkrZ33KKTh9+TS+nvA1quuqbZcrzXmRy0nYVLgJ+efzAQD55/Pxt+//hnk75sFoMDrkm4gnVaPBiKlZU112tzjnZYj1QTxxlxdkT2mAKTfL4g9SMzf7Tu3DW9+8hZdueQmDOg1ymLnZVLhJsv2Cu8AjkEE8kT8xh4XCTqDX1b3ZxXJN82tw+eXLMBgMbnda2PeOMRgMmucUKGnsCAAZ7TKw6n5r/xrn2zvvxmpmbAZzo1n2vroldMOxi8ccdrc4349cfRBnzvkbnrb6llaVegwwg1UbJPt4Np7d8CwssODYhWMuu38EQUCPpT1k+0XJjduf+TdEvmIOC0W0QK+r239LVjpbcbX+KjYUbMAvr/+lxwq2SnvHqKnLIRJnHTy58OMFyTFI7cZqbHS/rCWecO1nBJzvR64+iDP7mYUR149wWFIaljZMclmnQ8sOivJwAlkbRFwOO3LhiO0y5xkTc4MZxyuPy96H3Lj9lX9DFGicYSHSiJp6F/YzA6eqT/k8I+RLVd/SqlIcOndItj5KQkwCeib2dBmDpx03njhXQ/X2fsSZhblD52LUmlG2y93tHHK3a0ZcYgrk7hapnULOs0eedhMFY9xEvlJz/mbAQqQRb5aGtCq/7nwy07Ksu9LHlCPVEdje/DvmY+a2mT6NJbGldakqrzzPY6FAcSaqUWhE0cUiv29998RToJv1SBZGXD9CUZE2lrinUMOAhShIpHJIxF00RyqOuCShanFy9LWqry+P6Wk2STyRys2iiLkqtfW18jk87dLx1i/fQqW50na5c6+e/PP5eGztYy63l6phomVdFy24C/zEv+XOx3d6rMDbJqYNyp4v49IOhRTmsBAFiVT+jP0uGntabSn1taqvN5TuuLHA4nbHj6dcFQECLtZexPAuw2VPxGoqxWpd18VXnnbwiH9LTxV488/nu93yThQOOMNC5AWlCa5K+614OxsSyKq+zsTZJLEEv9yuGwMMaNG8hcdZlFX3r5Icq6ccHqWVYtXk3ARq14ySZTW594hUo8xAzgwRaSGoMyyZmZn47LPPcOTIEbRo0QK33HIL3nzzTXTv3l32NitWrMATTzzhcFl0dDRqa2u1Hh6Rz5wLnEntRhH5uy5MMAuCibNJ5gaz2103AgTUNkgHK+LvL9Yq2wnlclsVNUbkXqspA6fgib6Ox59A7JoRx+6pw7XUe0QQBMzInuEQrCitJkwUqjQPWHbs2IHJkydj4MCBaGhowCuvvIIRI0YgPz8fLVu2lL1dbGwsjh49avs3P3CkV2oaz/lzS6leCoIpeY4NlgY0M8ofbrx9DZQGhM6tAux9nPcx3r3zXRiNRtWP7wtx7O6ClbYt2mL92PXoFNfJ4fXZXLTZpXYOq9ZSuNM8YMnKynL494oVK9ChQwfk5ubiZz/7meztDAYDkpKSZH9PpAfOZfSVfKv1V12YQFb19SRYPWWUBoTOrQLsXa2/iszdmfjDz/7gr2FKUjp2qe3kM7dK76riLAuFM78n3VZVVQEAEhIS3F6vpqYGnTt3hsViQb9+/bBgwQLceOONktc1m80wm5sqaVZXV0tej0hrwUhwlcOCYFaegiVBEDDmkzFuewgt2L0AM26bEfBZFm8CPanZFRFnWSic+TXp1mKx4N5770VlZSV2794te709e/agoKAAvXr1QlVVFd5++23s3LkT//3vf9Gpk2uy3ezZszFnzhyXy5l0S/4UzARX8p7S+jhfPPQF7ul+T4BG5R0lrRRYk4VCiW7qsDz99NPYuHEjdu/eLRl4yKmvr0d6ejrGjh2LefPmufxeaoYlJSWFAQv5ldLdKKQ/zjuajlQccZhtCZWTvNJifewNRKFCTcDit/nPKVOmYP369di2bZuqYAUAmjdvjr59+6KwsFDy99HR0YiNjXX4IfIn+wRXKWKCaxhUCQhLKXEp6NexHyquViC/It9laUisF7O5aHOQRuiZp/egAQZktMtAzqQcHJh0gMEKhR3NAxZBEDBlyhSsXbsWW7duRVpamur7aGxsxKFDh9CxY0eth0fkFTUJrqRPgQg6s49nI2NZBrKPZ3t9H3I8vQftt4eznxCFI82TbidPnow1a9bg888/R+vWrVFeXg4AiIuLQ4sWLQAA48aNw7XXXovMzEwAwNy5czF48GDccMMNqKysxMKFC3Hy5Ek8+eSTWg+PyCtMcA19/t5VpaY+jzf4HqRIp3nA8v777wMAhg4d6nD58uXL8fjjjwMASkpKHLLxL126hEmTJqG8vBxt2rRB//798c033yAjI0Pr4RF5LVhbd0kb/j7hq6nP4y2+BymSsTQ/UZApLfNP+hWMBpRE4UAXSbdE5JnzMkIYfH+ISOLsirjd3b4eChFpgwELURBJLSNQaLGvfmxPrDrLIJRIGwxYiILE+UTHE1xocp5dEXGWhUhbDFiIgoTLCKGP9XmIAocBC1EQcBkhPLA+D1Hg+L35IRG5cm6iKGLzutDC2ihEgcOAhSjA7JcRpL6Zi8sII64fwS2xIYC1UYgCg0tCRAHGZQQiIvU4w0IUYFxGICJSjwELURBwGYGISB0uCREREZHuMWAhIiIi3WPAQkRERLrHgIWIiIh0jwELERER6R4DFiIiItI9BixERESkewxYiIiISPcYsBAREZHuhUWlW0EQAADV1dVBHgkREREpJZ63xfO4O2ERsFy+fBkAkJLCUudERESh5vLly4iLi3N7HYOgJKzROYvFgjNnzkAQBKSmpqK0tBSxsbHBHhY5qa6uRkpKCv8+OsW/j/7xb6Rv/PuoJwgCLl++jOTkZBiN7rNUwmKGxWg0olOnTrappdjYWL5ZdIx/H33j30f/+DfSN/591PE0syJi0i0RERHpHgMWIiIi0r2wCliio6Px2muvITo6OthDIQn8++gb/z76x7+RvvHv419hkXRLRERE4S2sZliIiIgoPDFgISIiIt1jwEJERES6x4CFiIiIdI8BCxEREeleWAUsy5Ytw3XXXYeYmBgMGjQI+/fvD/aQCEBmZiYGDhyI1q1bo0OHDhg9ejSOHj0a7GGRjDfeeAMGgwHTpk0L9lDoJ6dPn8ajjz6Ktm3bokWLFujZsydycnKCPSwC0NjYiFmzZiEtLQ0tWrTA9ddfj3nz5ilq5kfqhE3A8sknn2D69Ol47bXXcPDgQfTu3RsjR47EuXPngj20iLdjxw5MnjwZe/fuxVdffYX6+nqMGDECV65cCfbQyMmBAwfw5z//Gb169Qr2UOgnly5dwq233ormzZtj48aNyM/PxzvvvIM2bdoEe2gE4M0338T777+PpUuX4vDhw3jzzTfx1ltvYcmSJcEeWtgJmzosgwYNwsCBA7F06VIA1oaIKSkpePbZZ/Hyyy8HeXRk7/z58+jQoQN27NiBn/3sZ8EeDv2kpqYG/fr1w3vvvYf58+ejT58+WLRoUbCHFfFefvllfP3119i1a1ewh0ISfvWrXyExMREfffSR7bIHHngALVq0wOrVq4M4svATFjMsdXV1yM3NxfDhw22XGY1GDB8+HHv27AniyEhKVVUVACAhISHIIyF7kydPxt133+3wOaLg++KLLzBgwAA8+OCD6NChA/r27Yu//OUvwR4W/eSWW27Bli1bcOzYMQDAd999h927d2PUqFFBHln4CYtuzRUVFWhsbERiYqLD5YmJiThy5EiQRkVSLBYLpk2bhltvvRU33XRTsIdDP/nHP/6BgwcP4sCBA8EeCjk5fvw43n//fUyfPh2vvPIKDhw4gOeeew5RUVEYP358sIcX8V5++WVUV1ejR48eMJlMaGxsxOuvv45HHnkk2EMLO2ERsFDomDx5Mn744Qfs3r072EOhn5SWlmLq1Kn46quvEBMTE+zhkBOLxYIBAwZgwYIFAIC+ffvihx9+wAcffMCARQc+/fRT/N///R/WrFmDG2+8EXl5eZg2bRqSk5P599FYWAQs7dq1g8lkwtmzZx0uP3v2LJKSkoI0KnI2ZcoUrF+/Hjt37kSnTp2CPRz6SW5uLs6dO4d+/frZLmtsbMTOnTuxdOlSmM1mmEymII4wsnXs2BEZGRkOl6Wnp+Pf//53kEZE9l588UW8/PLLeOihhwAAPXv2xMmTJ5GZmcmARWNhkcMSFRWF/v37Y8uWLbbLLBYLtmzZgiFDhgRxZAQAgiBgypQpWLt2LbZu3Yq0tLRgD4nsDBs2DIcOHUJeXp7tZ8CAAXjkkUeQl5fHYCXIbr31VpcyAMeOHUPnzp2DNCKyd/XqVRiNjqdSk8kEi8USpBGFr7CYYQGA6dOnY/z48RgwYABuvvlmLFq0CFeuXMETTzwR7KFFvMmTJ2PNmjX4/PPP0bp1a5SXlwMA4uLi0KJFiyCPjlq3bu2ST9SyZUu0bduWeUY68L//+7+45ZZbsGDBAvzP//wP9u/fjw8//BAffvhhsIdGAO655x68/vrrSE1NxY033ohvv/0Wf/zjHzFhwoRgDy38CGFkyZIlQmpqqhAVFSXcfPPNwt69e4M9JBIEAYDkz/Lly4M9NJLx85//XJg6dWqwh0E/+c9//iPcdNNNQnR0tNCjRw/hww8/DPaQ6CfV1dXC1KlThdTUVCEmJkbo0qWL8Ic//EEwm83BHlrYCZs6LERERBS+wiKHhYiIiMIbAxYiIiLSPQYsREREpHsMWIiIiEj3GLAQERGR7jFgISIiIt1jwEJERES6x4CFiIiIdI8BCxEREekeAxYiIiLSPQYsREREpHv/DycA293lCQbXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(X, columns=[\"x1\", \"x2\"])\n",
        "data[\"y\"]=y"
      ],
      "metadata": {
        "id": "zT24y--afLHU"
      },
      "execution_count": 667,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"Q2Dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "mNKEksbQfYWZ"
      },
      "execution_count": 678,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.random.rand(data.shape[1]-1)\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaYf_PDPrmqP",
        "outputId": "4c97ef52-4df9-4dd7-f082-7c561dcfa740"
      },
      "execution_count": 669,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.75798771, 0.30654611])"
            ]
          },
          "metadata": {},
          "execution_count": 669
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reading Data"
      ],
      "metadata": {
        "id": "zs__1JeJ26DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Q2Dataset.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Xo-TM-Di3AZZ",
        "outputId": "e53e5f4c-fe78-4cbb-8f34-549177a12ae9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            x1         x2  y\n",
              "0     2.605446  14.302660  1\n",
              "1     5.177405   3.231283 -1\n",
              "2     5.837689   3.798322 -1\n",
              "3     3.783833  15.834580  1\n",
              "4     4.468544   5.576403 -1\n",
              "...        ...        ... ..\n",
              "4995  3.648918  15.301408  1\n",
              "4996  3.916278   4.460764 -1\n",
              "4997  4.639271  16.177760  1\n",
              "4998  3.883838  17.011286  1\n",
              "4999  5.298143  17.919666  1\n",
              "\n",
              "[5000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ad3176d-dc62-4477-9001-02ff70651f8b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.605446</td>\n",
              "      <td>14.302660</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.177405</td>\n",
              "      <td>3.231283</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.837689</td>\n",
              "      <td>3.798322</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.783833</td>\n",
              "      <td>15.834580</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.468544</td>\n",
              "      <td>5.576403</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>3.648918</td>\n",
              "      <td>15.301408</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>3.916278</td>\n",
              "      <td>4.460764</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>4.639271</td>\n",
              "      <td>16.177760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>3.883838</td>\n",
              "      <td>17.011286</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>5.298143</td>\n",
              "      <td>17.919666</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ad3176d-dc62-4477-9001-02ff70651f8b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ad3176d-dc62-4477-9001-02ff70651f8b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ad3176d-dc62-4477-9001-02ff70651f8b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-512686e7-bbee-42e3-a204-22e178bb4afd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-512686e7-bbee-42e3-a204-22e178bb4afd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-512686e7-bbee-42e3-a204-22e178bb4afd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0251857117318153,\n        \"min\": 0.4011217308524797,\n        \"max\": 9.058500612031828,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          4.2604162928432,\n          4.040576266719938,\n          3.3891589843643004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.202717820752454,\n        \"min\": 1.942559363913959,\n        \"max\": 19.34227692233874,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          3.872844786839603,\n          5.7749941248482575,\n          5.677458114362341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -1,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perceptron"
      ],
      "metadata": {
        "id": "yjaNYNJ26ei1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bias=1\n",
        "learning_rate = 0.1\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "LxSlLiL5WPN5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_activation(weighted_sum):\n",
        "  return np.where(weighted_sum>0.5,1 , -1)\n",
        "\n",
        "def update_weights(row_j, weights, learning_rate, target, prediction):\n",
        "  updated_weights = []\n",
        "  for row, weight in zip(row_j, weights):\n",
        "    updated_weights.append(weight+learning_rate*(target-prediction)*row)\n",
        "  return updated_weights"
      ],
      "metadata": {
        "id": "yCwxudNPeUYu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(data, labels, learning_rate=0.01, epochs=10):\n",
        "  t = 0\n",
        "  correct_pred = 0\n",
        "  weights = np.array([0.75798771, 0.30654611])\n",
        "  epoch_loss= []\n",
        "  epoch_accuracy = []\n",
        "  classification_error = 0\n",
        "  while True:\n",
        "    iter_loss = []\n",
        "    classification_error = 0\n",
        "    correct_pred = 0\n",
        "    for j in range(len(data)):\n",
        "      row_j = data.iloc[j]\n",
        "      target = labels.iloc[j]\n",
        "      weighted_sum = np.dot(row_j, weights)+1\n",
        "      prediction = perceptron_activation(weighted_sum)\n",
        "      if(prediction==target):\n",
        "        correct_pred+=1\n",
        "      classification_error += (1/len(data))*(abs(1/2*(target-prediction)))\n",
        "      weights = update_weights(row_j, weights, learning_rate, target, prediction)\n",
        "    t=t+1\n",
        "    accuracy = correct_pred/len(data)\n",
        "    epoch_accuracy.append(accuracy)\n",
        "    epoch_loss.append(classification_error)\n",
        "    print(f\"Epoch {t} loss: {classification_error}\")\n",
        "    print(f\"Epoch {t} accuracy: {accuracy}\")\n",
        "    print(f\"Weight: {weights}\", \"\\n\")\n",
        "\n",
        "    if(classification_error <= 0.10 and t<30):\n",
        "      return weights\n",
        "      break;\n",
        "\n",
        "\n",
        "  print(f\"\\nAverage loss of all epochs {sum(epoch_loss)/len(epoch_loss)}\")\n",
        "  return weights\n",
        "\n",
        "\n",
        "def pred_perceptron(data, weights):\n",
        "  w_sum =  np.dot(data, weights)\n",
        "  return perceptron_activation(w_sum)"
      ],
      "metadata": {
        "id": "3xK20M_VekCO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data , test_size=0.2, random_state=42)\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "jH5mIadje5CV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mse_scores = []\n",
        "\n",
        "save_weights = []\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(f\"****************** K-FOLD: {len(mse_scores)+1} ******************\")\n",
        "    train_data, val_data = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    train_labels, val_labels = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    weights = perceptron(train_data, train_labels)\n",
        "    save_weights.append(weights)\n",
        "\n",
        "    val_pred = pred_perceptron(val_data, weights)\n",
        "    val_mse = mean_squared_error(val_labels, val_pred)\n",
        "    mse_scores.append(val_mse)\n",
        "\n",
        "average_loss = sum(mse_scores)/len(mse_scores)\n",
        "print(\"Average Validation Loss:\", average_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bBEzTDrfko7",
        "outputId": "d2823bcc-c276-4ab2-e514-068862e87ab4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************** K-FOLD: 1 ******************\n",
            "Epoch 1 loss: 0.059444444444444536\n",
            "Epoch 1 accuracy: 0.9405555555555556\n",
            "Weight: [-1.9506886202739564, 0.9456374917359338] \n",
            "\n",
            "****************** K-FOLD: 2 ******************\n",
            "Epoch 1 loss: 0.05833333333333342\n",
            "Epoch 1 accuracy: 0.9416666666666667\n",
            "Weight: [-1.946699075861729, 0.9345850858111171] \n",
            "\n",
            "****************** K-FOLD: 3 ******************\n",
            "Epoch 1 loss: 0.05611111111111118\n",
            "Epoch 1 accuracy: 0.9438888888888889\n",
            "Weight: [-1.8760023174022067, 0.9972018484519933] \n",
            "\n",
            "****************** K-FOLD: 4 ******************\n",
            "Epoch 1 loss: 0.060000000000000095\n",
            "Epoch 1 accuracy: 0.94\n",
            "Weight: [-2.010089737603247, 1.0635643157803074] \n",
            "\n",
            "****************** K-FOLD: 5 ******************\n",
            "Epoch 1 loss: 0.05694444444444452\n",
            "Epoch 1 accuracy: 0.9430555555555555\n",
            "Weight: [-1.9493622162734687, 0.9913028791847809] \n",
            "\n",
            "****************** K-FOLD: 6 ******************\n",
            "Epoch 1 loss: 0.05666666666666674\n",
            "Epoch 1 accuracy: 0.9433333333333334\n",
            "Weight: [-1.9090679821160201, 0.8592892542613697] \n",
            "\n",
            "****************** K-FOLD: 7 ******************\n",
            "Epoch 1 loss: 0.0572222222222223\n",
            "Epoch 1 accuracy: 0.9427777777777778\n",
            "Weight: [-1.9431209044239586, 0.9434420914044277] \n",
            "\n",
            "****************** K-FOLD: 8 ******************\n",
            "Epoch 1 loss: 0.05777777777777786\n",
            "Epoch 1 accuracy: 0.9422222222222222\n",
            "Weight: [-1.8795174253419054, 0.9929075341078761] \n",
            "\n",
            "****************** K-FOLD: 9 ******************\n",
            "Epoch 1 loss: 0.059444444444444536\n",
            "Epoch 1 accuracy: 0.9405555555555556\n",
            "Weight: [-1.9604334886530956, 0.8327055194918338] \n",
            "\n",
            "****************** K-FOLD: 10 ******************\n",
            "Epoch 1 loss: 0.060555555555555654\n",
            "Epoch 1 accuracy: 0.9394444444444444\n",
            "Weight: [-1.958380890390939, 0.9396882063532017] \n",
            "\n",
            "Average Validation Loss: 0.06000000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u_z-Qj0kweb",
        "outputId": "18f37cff-4a79-4416-aeeb-91106f780d9f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-1.9506886202739564, 0.9456374917359338],\n",
              " [-1.946699075861729, 0.9345850858111171],\n",
              " [-1.8760023174022067, 0.9972018484519933],\n",
              " [-2.010089737603247, 1.0635643157803074],\n",
              " [-1.9493622162734687, 0.9913028791847809],\n",
              " [-1.9090679821160201, 0.8592892542613697],\n",
              " [-1.9431209044239586, 0.9434420914044277],\n",
              " [-1.8795174253419054, 0.9929075341078761],\n",
              " [-1.9604334886530956, 0.8327055194918338],\n",
              " [-1.958380890390939, 0.9396882063532017]]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred=0\n",
        "classification_error=0\n",
        "predA = []\n",
        "for j in range(len(X_test)):\n",
        "  row_j = X_test.iloc[j]\n",
        "  target = y_test.iloc[j]\n",
        "  weighted_sum = np.dot(row_j, save_weights[5])+1\n",
        "  prediction = perceptron_activation(weighted_sum)\n",
        "  predA.append(prediction)\n",
        "  if(prediction==target):\n",
        "    correct_pred+=1\n",
        "  classification_error += (1/len(data))*(abs(1/2*(y_test-prediction)))\n",
        "\n",
        "accuracy = correct_pred/len(X_test)\n",
        "print(\"Accuracy on test set is\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUBoctjIoONB",
        "outputId": "025b01d5-6c0f-445f-f3dc-d1f0bc91eea0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set is 0.982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pocket Algorithm"
      ],
      "metadata": {
        "id": "Ya8cHlC66U4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "lldru5G36mS-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_activation(weighted_sum):\n",
        "  return np.where(weighted_sum>0.5,1 , -1)\n",
        "\n",
        "def update_weights(row_j, weights, learning_rate, target, prediction):\n",
        "  updated_weights = []\n",
        "  for row, weight in zip(row_j, weights):\n",
        "    updated_weights.append(weight+learning_rate*(target-prediction)*row)\n",
        "  return updated_weights"
      ],
      "metadata": {
        "id": "Hmr-Sk4H6Yl7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pocket_algorithm(data, labels, learning_rate=0.01, epochs=20):\n",
        "  t = 0\n",
        "  correct_pred = 0\n",
        "  weights = np.array([0.03798771, 0.0654611])\n",
        "  best_weights = weights.copy()\n",
        "  best_classification_error=float('inf')\n",
        "  epoch_loss= []\n",
        "  classification_error = 0\n",
        "  epoch_accuracy = []\n",
        "  for i in range(epochs):\n",
        "    iter_loss = []\n",
        "    classification_error = 0\n",
        "    correct_pred = 0\n",
        "    for j in range(len(data)):\n",
        "      row_j = data.iloc[j]\n",
        "      target = labels.iloc[j]\n",
        "      weighted_sum = np.dot(row_j, weights)+1\n",
        "      prediction = perceptron_activation(weighted_sum)\n",
        "      if(prediction==target):\n",
        "        correct_pred+=1\n",
        "      classification_error += (1/len(data))*(abs(1/2*(target-prediction)))\n",
        "      weights = update_weights(row_j, weights, learning_rate, target, prediction)\n",
        "    t=t+1\n",
        "    accuracy = correct_pred/len(data)\n",
        "    epoch_accuracy.append(accuracy)\n",
        "    epoch_loss.append(classification_error)\n",
        "    print(f\"Epoch {i+1} loss: {classification_error}\")\n",
        "    print(f\"Epoch {i+1} accuracy: {accuracy}\")\n",
        "    print(f\"Weight: {weights}\", \"\\n\")\n",
        "\n",
        "\n",
        "    if classification_error<best_classification_error:\n",
        "      best_classification_error=classification_error\n",
        "      best_weights=weights.copy()\n",
        "\n",
        "    if(classification_error == 0.0 and t<30):\n",
        "      return best_weights\n",
        "      break;\n",
        "\n",
        "  print(f\"Best Weights: {best_weights}\")\n",
        "  print(f\"Lowest error: {best_classification_error}\",\"\\n\")\n",
        "  # print(f\"\\nAverage loss of all epochs {sum(epoch_loss)/len(epoch_loss)}\")\n",
        "  return best_weights\n",
        "\n",
        "\n",
        "def pred_perceptron(data, weights):\n",
        "  w_sum =  np.dot(data, weights)\n",
        "  return perceptron_activation(w_sum)"
      ],
      "metadata": {
        "id": "am6dbdbX6wv5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data , test_size=0.2, random_state=42)\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "oMWmB82_iOAy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mse_scores = []\n",
        "\n",
        "save_weights=[]\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(f\"****************** K-FOLD: {len(mse_scores)+1} ******************\")\n",
        "    train_data, val_data = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    train_labels, val_labels = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    weights = pocket_algorithm(train_data, train_labels)\n",
        "    save_weights.append(weights)\n",
        "\n",
        "\n",
        "    val_pred = pred_perceptron(val_data, weights)\n",
        "    val_mse = mean_squared_error(val_labels, val_pred)\n",
        "    mse_scores.append(val_mse)\n",
        "\n",
        "average_loss = sum(mse_scores)/len(mse_scores)\n",
        "print(\"Average Validation Loss:\", average_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYwL8uzAiODb",
        "outputId": "72b0df0c-cd42-4fff-d21e-bd97771076d2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************** K-FOLD: 1 ******************\n",
            "Epoch 1 loss: 0.05222222222222227\n",
            "Epoch 1 accuracy: 0.9477777777777778\n",
            "Weight: [-1.9205216247668373, 0.9341454137679781] \n",
            "\n",
            "Epoch 2 loss: 0.03972222222222219\n",
            "Epoch 2 accuracy: 0.9602777777777778\n",
            "Weight: [-2.3032997052438975, 1.2348624299564095] \n",
            "\n",
            "Epoch 3 loss: 0.03166666666666658\n",
            "Epoch 3 accuracy: 0.9683333333333334\n",
            "Weight: [-2.4283625798631165, 1.2848370720378612] \n",
            "\n",
            "Epoch 4 loss: 0.03027777777777769\n",
            "Epoch 4 accuracy: 0.9697222222222223\n",
            "Weight: [-2.526750834097301, 1.3281228667714406] \n",
            "\n",
            "Epoch 5 loss: 0.029999999999999916\n",
            "Epoch 5 accuracy: 0.97\n",
            "Weight: [-2.5787606764025863, 1.4083296619395724] \n",
            "\n",
            "Epoch 6 loss: 0.03027777777777769\n",
            "Epoch 6 accuracy: 0.9697222222222223\n",
            "Weight: [-2.6112223503616616, 1.3815636468748773] \n",
            "\n",
            "Epoch 7 loss: 0.029999999999999916\n",
            "Epoch 7 accuracy: 0.97\n",
            "Weight: [-2.6641157765878676, 1.4556948416247633] \n",
            "\n",
            "Epoch 8 loss: 0.02972222222222214\n",
            "Epoch 8 accuracy: 0.9702777777777778\n",
            "Weight: [-2.6880492957925726, 1.4722212515624544] \n",
            "\n",
            "Epoch 9 loss: 0.02888888888888881\n",
            "Epoch 9 accuracy: 0.9711111111111111\n",
            "Weight: [-2.676383851738795, 1.4385177369561781] \n",
            "\n",
            "Epoch 10 loss: 0.030833333333333244\n",
            "Epoch 10 accuracy: 0.9691666666666666\n",
            "Weight: [-2.6858139068549836, 1.4418908901842935] \n",
            "\n",
            "Epoch 11 loss: 0.03166666666666658\n",
            "Epoch 11 accuracy: 0.9683333333333334\n",
            "Weight: [-2.7159151440880605, 1.483717049907862] \n",
            "\n",
            "Epoch 12 loss: 0.02888888888888881\n",
            "Epoch 12 accuracy: 0.9711111111111111\n",
            "Weight: [-2.7042497000342833, 1.4500135353015853] \n",
            "\n",
            "Epoch 13 loss: 0.030833333333333244\n",
            "Epoch 13 accuracy: 0.9691666666666666\n",
            "Weight: [-2.713679755150472, 1.4533866885297007] \n",
            "\n",
            "Epoch 14 loss: 0.030833333333333244\n",
            "Epoch 14 accuracy: 0.9691666666666666\n",
            "Weight: [-2.72310981026666, 1.456759841757816] \n",
            "\n",
            "Epoch 15 loss: 0.03222222222222214\n",
            "Epoch 15 accuracy: 0.9677777777777777\n",
            "Weight: [-2.7883684188692275, 1.4732785581429544] \n",
            "\n",
            "Epoch 16 loss: 0.029166666666666587\n",
            "Epoch 16 accuracy: 0.9708333333333333\n",
            "Weight: [-2.737714856829756, 1.4674262377037806] \n",
            "\n",
            "Epoch 17 loss: 0.030833333333333244\n",
            "Epoch 17 accuracy: 0.9691666666666666\n",
            "Weight: [-2.747144911945944, 1.470799390931896] \n",
            "\n",
            "Epoch 18 loss: 0.030833333333333244\n",
            "Epoch 18 accuracy: 0.9691666666666666\n",
            "Weight: [-2.7565749670621322, 1.4741725441600113] \n",
            "\n",
            "Epoch 19 loss: 0.03111111111111102\n",
            "Epoch 19 accuracy: 0.9688888888888889\n",
            "Weight: [-2.739922933238245, 1.488106632291965] \n",
            "\n",
            "Epoch 20 loss: 0.029166666666666587\n",
            "Epoch 20 accuracy: 0.9708333333333333\n",
            "Weight: [-2.712582538199367, 1.4523302703311762] \n",
            "\n",
            "Best Weights: [-2.676383851738795, 1.4385177369561781]\n",
            "Lowest error: 0.02888888888888881 \n",
            "\n",
            "****************** K-FOLD: 2 ******************\n",
            "Epoch 1 loss: 0.0558333333333334\n",
            "Epoch 1 accuracy: 0.9441666666666667\n",
            "Weight: [-1.9184622732343493, 0.9215926034648203] \n",
            "\n",
            "Epoch 2 loss: 0.03833333333333329\n",
            "Epoch 2 accuracy: 0.9616666666666667\n",
            "Weight: [-2.280006822572571, 1.1492667499671674] \n",
            "\n",
            "Epoch 3 loss: 0.03166666666666658\n",
            "Epoch 3 accuracy: 0.9683333333333334\n",
            "Weight: [-2.3805144564116034, 1.2644229978335102] \n",
            "\n",
            "Epoch 4 loss: 0.03555555555555549\n",
            "Epoch 4 accuracy: 0.9644444444444444\n",
            "Weight: [-2.5866139041098104, 1.2968584836286376] \n",
            "\n",
            "Epoch 5 loss: 0.02888888888888881\n",
            "Epoch 5 accuracy: 0.9711111111111111\n",
            "Weight: [-2.5532043102122564, 1.400897661641879] \n",
            "\n",
            "Epoch 6 loss: 0.03111111111111102\n",
            "Epoch 6 accuracy: 0.9688888888888889\n",
            "Weight: [-2.6059215273167253, 1.4192874351851426] \n",
            "\n",
            "Epoch 7 loss: 0.03111111111111102\n",
            "Epoch 7 accuracy: 0.9688888888888889\n",
            "Weight: [-2.655530151069066, 1.4457523899006095] \n",
            "\n",
            "Epoch 8 loss: 0.029999999999999916\n",
            "Epoch 8 accuracy: 0.97\n",
            "Weight: [-2.671366544862295, 1.456121215272505] \n",
            "\n",
            "Epoch 9 loss: 0.029999999999999916\n",
            "Epoch 9 accuracy: 0.97\n",
            "Weight: [-2.6872029386555245, 1.4664900406444004] \n",
            "\n",
            "Epoch 10 loss: 0.029999999999999916\n",
            "Epoch 10 accuracy: 0.97\n",
            "Weight: [-2.703039332448754, 1.4768588660162958] \n",
            "\n",
            "Epoch 11 loss: 0.029166666666666587\n",
            "Epoch 11 accuracy: 0.9708333333333333\n",
            "Weight: [-2.7135858648884557, 1.4879408927548694] \n",
            "\n",
            "Epoch 12 loss: 0.029999999999999916\n",
            "Epoch 12 accuracy: 0.97\n",
            "Weight: [-2.8022094408392335, 1.3923032406754634] \n",
            "\n",
            "Epoch 13 loss: 0.02972222222222214\n",
            "Epoch 13 accuracy: 0.9702777777777778\n",
            "Weight: [-2.738080451800497, 1.4907309003844744] \n",
            "\n",
            "Epoch 14 loss: 0.029999999999999916\n",
            "Epoch 14 accuracy: 0.97\n",
            "Weight: [-2.7327025155992843, 1.486289116011022] \n",
            "\n",
            "Epoch 15 loss: 0.029999999999999916\n",
            "Epoch 15 accuracy: 0.97\n",
            "Weight: [-2.7485389093925137, 1.4966579413829175] \n",
            "\n",
            "Epoch 16 loss: 0.029999999999999916\n",
            "Epoch 16 accuracy: 0.97\n",
            "Weight: [-2.743160973191301, 1.4922161570094652] \n",
            "\n",
            "Epoch 17 loss: 0.029999999999999916\n",
            "Epoch 17 accuracy: 0.97\n",
            "Weight: [-2.737783036990088, 1.4877743726360129] \n",
            "\n",
            "Epoch 18 loss: 0.029166666666666587\n",
            "Epoch 18 accuracy: 0.9708333333333333\n",
            "Weight: [-2.7274452902617345, 1.4789047431964721] \n",
            "\n",
            "Epoch 19 loss: 0.029166666666666587\n",
            "Epoch 19 accuracy: 0.9708333333333333\n",
            "Weight: [-2.7108245232863895, 1.4846460404262618] \n",
            "\n",
            "Epoch 20 loss: 0.029999999999999916\n",
            "Epoch 20 accuracy: 0.97\n",
            "Weight: [-2.7994480992371673, 1.3890083883468558] \n",
            "\n",
            "Best Weights: [-2.5532043102122564, 1.400897661641879]\n",
            "Lowest error: 0.02888888888888881 \n",
            "\n",
            "****************** K-FOLD: 3 ******************\n",
            "Epoch 1 loss: 0.054444444444444504\n",
            "Epoch 1 accuracy: 0.9455555555555556\n",
            "Weight: [-1.9878774010989089, 0.8851698728528221] \n",
            "\n",
            "Epoch 2 loss: 0.03972222222222219\n",
            "Epoch 2 accuracy: 0.9602777777777778\n",
            "Weight: [-2.3062819440304967, 1.1290991288429741] \n",
            "\n",
            "Epoch 3 loss: 0.03638888888888883\n",
            "Epoch 3 accuracy: 0.9636111111111111\n",
            "Weight: [-2.4344598982369416, 1.3214107834054] \n",
            "\n",
            "Epoch 4 loss: 0.034166666666666595\n",
            "Epoch 4 accuracy: 0.9658333333333333\n",
            "Weight: [-2.646469512571725, 1.2022313195643906] \n",
            "\n",
            "Epoch 5 loss: 0.0327777777777777\n",
            "Epoch 5 accuracy: 0.9672222222222222\n",
            "Weight: [-2.724227435096804, 1.2700627965850095] \n",
            "\n",
            "Epoch 6 loss: 0.03111111111111102\n",
            "Epoch 6 accuracy: 0.9688888888888889\n",
            "Weight: [-2.7624949127632368, 1.2864231282303755] \n",
            "\n",
            "Epoch 7 loss: 0.03111111111111102\n",
            "Epoch 7 accuracy: 0.9688888888888889\n",
            "Weight: [-2.8007623904296697, 1.302783459875742] \n",
            "\n",
            "Epoch 8 loss: 0.03194444444444436\n",
            "Epoch 8 accuracy: 0.9680555555555556\n",
            "Weight: [-2.861327774962229, 1.322428897856] \n",
            "\n",
            "Epoch 9 loss: 0.03027777777777769\n",
            "Epoch 9 accuracy: 0.9697222222222223\n",
            "Weight: [-2.8805874737023585, 1.3234099181631376] \n",
            "\n",
            "Epoch 10 loss: 0.02972222222222214\n",
            "Epoch 10 accuracy: 0.9702777777777778\n",
            "Weight: [-2.8971148091444303, 1.33045245380441] \n",
            "\n",
            "Epoch 11 loss: 0.02972222222222214\n",
            "Epoch 11 accuracy: 0.9702777777777778\n",
            "Weight: [-2.9136421445865017, 1.3374949894456825] \n",
            "\n",
            "Epoch 12 loss: 0.02972222222222214\n",
            "Epoch 12 accuracy: 0.9702777777777778\n",
            "Weight: [-2.930169480028573, 1.344537525086955] \n",
            "\n",
            "Epoch 13 loss: 0.02972222222222214\n",
            "Epoch 13 accuracy: 0.9702777777777778\n",
            "Weight: [-2.9373031801603853, 1.3662606205872805] \n",
            "\n",
            "Epoch 14 loss: 0.029166666666666587\n",
            "Epoch 14 accuracy: 0.9708333333333333\n",
            "Weight: [-2.9470548222423547, 1.3708583900573605] \n",
            "\n",
            "Epoch 15 loss: 0.029166666666666587\n",
            "Epoch 15 accuracy: 0.9708333333333333\n",
            "Weight: [-2.956806464324324, 1.3754561595274406] \n",
            "\n",
            "Epoch 16 loss: 0.029999999999999916\n",
            "Epoch 16 accuracy: 0.97\n",
            "Weight: [-2.9467856409134647, 1.361413546976394] \n",
            "\n",
            "Epoch 17 loss: 0.0313888888888888\n",
            "Epoch 17 accuracy: 0.9686111111111111\n",
            "Weight: [-2.873209991551493, 1.564204108364658] \n",
            "\n",
            "Epoch 18 loss: 0.02833333333333326\n",
            "Epoch 18 accuracy: 0.9716666666666667\n",
            "Weight: [-2.947913244421893, 1.3697793571023673] \n",
            "\n",
            "Epoch 19 loss: 0.029166666666666587\n",
            "Epoch 19 accuracy: 0.9708333333333333\n",
            "Weight: [-2.9576648865038626, 1.3743771265724474] \n",
            "\n",
            "Epoch 20 loss: 0.029166666666666587\n",
            "Epoch 20 accuracy: 0.9708333333333333\n",
            "Weight: [-2.937765216837117, 1.365436734322589] \n",
            "\n",
            "Best Weights: [-2.947913244421893, 1.3697793571023673]\n",
            "Lowest error: 0.02833333333333326 \n",
            "\n",
            "****************** K-FOLD: 4 ******************\n",
            "Epoch 1 loss: 0.05777777777777786\n",
            "Epoch 1 accuracy: 0.9422222222222222\n",
            "Weight: [-2.0010959509478137, 1.0267275930728015] \n",
            "\n",
            "Epoch 2 loss: 0.03638888888888883\n",
            "Epoch 2 accuracy: 0.9636111111111111\n",
            "Weight: [-2.225813386493702, 1.1150532807408986] \n",
            "\n",
            "Epoch 3 loss: 0.035277777777777714\n",
            "Epoch 3 accuracy: 0.9647222222222223\n",
            "Weight: [-2.333069065388902, 1.2733630835118068] \n",
            "\n",
            "Epoch 4 loss: 0.03305555555555548\n",
            "Epoch 4 accuracy: 0.9669444444444445\n",
            "Weight: [-2.521066714110295, 1.220149302514002] \n",
            "\n",
            "Epoch 5 loss: 0.03249999999999992\n",
            "Epoch 5 accuracy: 0.9675\n",
            "Weight: [-2.538502751627246, 1.3926848266881489] \n",
            "\n",
            "Epoch 6 loss: 0.03249999999999992\n",
            "Epoch 6 accuracy: 0.9675\n",
            "Weight: [-2.6025358550014186, 1.4276407470366757] \n",
            "\n",
            "Epoch 7 loss: 0.0313888888888888\n",
            "Epoch 7 accuracy: 0.9686111111111111\n",
            "Weight: [-2.608715184568419, 1.4113254367603838] \n",
            "\n",
            "Epoch 8 loss: 0.030833333333333244\n",
            "Epoch 8 accuracy: 0.9691666666666666\n",
            "Weight: [-2.6390267204864015, 1.4486224103263494] \n",
            "\n",
            "Epoch 9 loss: 0.0313888888888888\n",
            "Epoch 9 accuracy: 0.9686111111111111\n",
            "Weight: [-2.645206050053402, 1.4323071000500571] \n",
            "\n",
            "Epoch 10 loss: 0.030833333333333244\n",
            "Epoch 10 accuracy: 0.9691666666666666\n",
            "Weight: [-2.640584854632166, 1.4289501134285556] \n",
            "\n",
            "Epoch 11 loss: 0.030833333333333244\n",
            "Epoch 11 accuracy: 0.9691666666666666\n",
            "Weight: [-2.6708963905501486, 1.4662470869945217] \n",
            "\n",
            "Epoch 12 loss: 0.0313888888888888\n",
            "Epoch 12 accuracy: 0.9686111111111111\n",
            "Weight: [-2.6792603260006747, 1.4618090956989354] \n",
            "\n",
            "Epoch 13 loss: 0.030555555555555468\n",
            "Epoch 13 accuracy: 0.9694444444444444\n",
            "Weight: [-2.690218489027627, 1.4663627442187595] \n",
            "\n",
            "Epoch 14 loss: 0.030555555555555468\n",
            "Epoch 14 accuracy: 0.9694444444444444\n",
            "Weight: [-2.7011766520545795, 1.4709163927385835] \n",
            "\n",
            "Epoch 15 loss: 0.030555555555555468\n",
            "Epoch 15 accuracy: 0.9694444444444444\n",
            "Weight: [-2.7050701099486023, 1.480034843666605] \n",
            "\n",
            "Epoch 16 loss: 0.0313888888888888\n",
            "Epoch 16 accuracy: 0.9686111111111111\n",
            "Weight: [-2.706369340266199, 1.4801616547792162] \n",
            "\n",
            "Epoch 17 loss: 0.0313888888888888\n",
            "Epoch 17 accuracy: 0.9686111111111111\n",
            "Weight: [-2.7076685705837953, 1.4802884658918274] \n",
            "\n",
            "Epoch 18 loss: 0.0313888888888888\n",
            "Epoch 18 accuracy: 0.9686111111111111\n",
            "Weight: [-2.7089678009013918, 1.4804152770044385] \n",
            "\n",
            "Epoch 19 loss: 0.029444444444444363\n",
            "Epoch 19 accuracy: 0.9705555555555555\n",
            "Weight: [-2.6857964071868072, 1.4513229546392965] \n",
            "\n",
            "Epoch 20 loss: 0.02972222222222214\n",
            "Epoch 20 accuracy: 0.9702777777777778\n",
            "Weight: [-2.702958143939762, 1.4735747162202146] \n",
            "\n",
            "Best Weights: [-2.6857964071868072, 1.4513229546392965]\n",
            "Lowest error: 0.029444444444444363 \n",
            "\n",
            "****************** K-FOLD: 5 ******************\n",
            "Epoch 1 loss: 0.053888888888888944\n",
            "Epoch 1 accuracy: 0.9461111111111111\n",
            "Weight: [-1.9569294401493833, 0.9451061502372385] \n",
            "\n",
            "Epoch 2 loss: 0.03611111111111105\n",
            "Epoch 2 accuracy: 0.9638888888888889\n",
            "Weight: [-2.211659297867181, 1.131639713620282] \n",
            "\n",
            "Epoch 3 loss: 0.03305555555555548\n",
            "Epoch 3 accuracy: 0.9669444444444445\n",
            "Weight: [-2.4390500794261483, 1.0894265981357574] \n",
            "\n",
            "Epoch 4 loss: 0.034722222222222154\n",
            "Epoch 4 accuracy: 0.9652777777777778\n",
            "Weight: [-2.6169065015848663, 1.1701536557507368] \n",
            "\n",
            "Epoch 5 loss: 0.03194444444444436\n",
            "Epoch 5 accuracy: 0.9680555555555556\n",
            "Weight: [-2.6956140786984775, 1.2048034557221192] \n",
            "\n",
            "Epoch 6 loss: 0.03194444444444436\n",
            "Epoch 6 accuracy: 0.9680555555555556\n",
            "Weight: [-2.743741240989421, 1.3367398530353494] \n",
            "\n",
            "Epoch 7 loss: 0.029999999999999916\n",
            "Epoch 7 accuracy: 0.97\n",
            "Weight: [-2.7320735286852416, 1.3264251555972997] \n",
            "\n",
            "Epoch 8 loss: 0.03027777777777769\n",
            "Epoch 8 accuracy: 0.9697222222222223\n",
            "Weight: [-2.730457253457079, 1.319075813231193] \n",
            "\n",
            "Epoch 9 loss: 0.029999999999999916\n",
            "Epoch 9 accuracy: 0.97\n",
            "Weight: [-2.691704598958208, 1.3047254395625052] \n",
            "\n",
            "Epoch 10 loss: 0.03027777777777769\n",
            "Epoch 10 accuracy: 0.9697222222222223\n",
            "Weight: [-2.690088323730045, 1.2973760971963986] \n",
            "\n",
            "Epoch 11 loss: 0.030833333333333244\n",
            "Epoch 11 accuracy: 0.9691666666666666\n",
            "Weight: [-2.687301713227116, 1.3062893150775858] \n",
            "\n",
            "Epoch 12 loss: 0.0313888888888888\n",
            "Epoch 12 accuracy: 0.9686111111111111\n",
            "Weight: [-2.7730628856774167, 1.2392064532941607] \n",
            "\n",
            "Epoch 13 loss: 0.03166666666666658\n",
            "Epoch 13 accuracy: 0.9683333333333334\n",
            "Weight: [-2.776217610378353, 1.3429827921054434] \n",
            "\n",
            "Epoch 14 loss: 0.029999999999999916\n",
            "Epoch 14 accuracy: 0.97\n",
            "Weight: [-2.7374649558794824, 1.3286324184367555] \n",
            "\n",
            "Epoch 15 loss: 0.03027777777777769\n",
            "Epoch 15 accuracy: 0.9697222222222223\n",
            "Weight: [-2.735848680651319, 1.3212830760706489] \n",
            "\n",
            "Epoch 16 loss: 0.029999999999999916\n",
            "Epoch 16 accuracy: 0.97\n",
            "Weight: [-2.6970960261524484, 1.306932702401961] \n",
            "\n",
            "Epoch 17 loss: 0.03027777777777769\n",
            "Epoch 17 accuracy: 0.9697222222222223\n",
            "Weight: [-2.695479750924285, 1.2995833600358544] \n",
            "\n",
            "Epoch 18 loss: 0.030833333333333244\n",
            "Epoch 18 accuracy: 0.9691666666666666\n",
            "Weight: [-2.6926931404213565, 1.3084965779170417] \n",
            "\n",
            "Epoch 19 loss: 0.0313888888888888\n",
            "Epoch 19 accuracy: 0.9686111111111111\n",
            "Weight: [-2.778454312871657, 1.2414137161336165] \n",
            "\n",
            "Epoch 20 loss: 0.03166666666666658\n",
            "Epoch 20 accuracy: 0.9683333333333334\n",
            "Weight: [-2.7816090375725935, 1.3451900549448992] \n",
            "\n",
            "Best Weights: [-2.7320735286852416, 1.3264251555972997]\n",
            "Lowest error: 0.029999999999999916 \n",
            "\n",
            "****************** K-FOLD: 6 ******************\n",
            "Epoch 1 loss: 0.05666666666666674\n",
            "Epoch 1 accuracy: 0.9433333333333334\n",
            "Weight: [-1.942291334668377, 0.9969870232992339] \n",
            "\n",
            "Epoch 2 loss: 0.03833333333333329\n",
            "Epoch 2 accuracy: 0.9616666666666667\n",
            "Weight: [-2.3072314271578676, 1.089584234495403] \n",
            "\n",
            "Epoch 3 loss: 0.0327777777777777\n",
            "Epoch 3 accuracy: 0.9672222222222222\n",
            "Weight: [-2.456735899677722, 1.2203206202729713] \n",
            "\n",
            "Epoch 4 loss: 0.03111111111111102\n",
            "Epoch 4 accuracy: 0.9688888888888889\n",
            "Weight: [-2.525983191265747, 1.2233294138884965] \n",
            "\n",
            "Epoch 5 loss: 0.033888888888888816\n",
            "Epoch 5 accuracy: 0.9661111111111111\n",
            "Weight: [-2.592500100111278, 1.2594118333737012] \n",
            "\n",
            "Epoch 6 loss: 0.03194444444444436\n",
            "Epoch 6 accuracy: 0.9680555555555556\n",
            "Weight: [-2.5874241541127083, 1.2560718977153869] \n",
            "\n",
            "Epoch 7 loss: 0.03194444444444436\n",
            "Epoch 7 accuracy: 0.9680555555555556\n",
            "Weight: [-2.5901906408726103, 1.2569738235381056] \n",
            "\n",
            "Epoch 8 loss: 0.03194444444444436\n",
            "Epoch 8 accuracy: 0.9680555555555556\n",
            "Weight: [-2.5929571276325123, 1.2578757493608244] \n",
            "\n",
            "Epoch 9 loss: 0.03194444444444436\n",
            "Epoch 9 accuracy: 0.9680555555555556\n",
            "Weight: [-2.5957236143924143, 1.258777675183543] \n",
            "\n",
            "Epoch 10 loss: 0.03194444444444436\n",
            "Epoch 10 accuracy: 0.9680555555555556\n",
            "Weight: [-2.5984901011523163, 1.2596796010062619] \n",
            "\n",
            "Epoch 11 loss: 0.03194444444444436\n",
            "Epoch 11 accuracy: 0.9680555555555556\n",
            "Weight: [-2.6012565879122183, 1.2605815268289806] \n",
            "\n",
            "Epoch 12 loss: 0.030833333333333244\n",
            "Epoch 12 accuracy: 0.9691666666666666\n",
            "Weight: [-2.5936753850603522, 1.2528720248671057] \n",
            "\n",
            "Epoch 13 loss: 0.033611111111111036\n",
            "Epoch 13 accuracy: 0.9663888888888889\n",
            "Weight: [-2.569741362222038, 1.396472077100886] \n",
            "\n",
            "Epoch 14 loss: 0.03305555555555548\n",
            "Epoch 14 accuracy: 0.9669444444444445\n",
            "Weight: [-2.6383037039254096, 1.2779747345989172] \n",
            "\n",
            "Epoch 15 loss: 0.030833333333333244\n",
            "Epoch 15 accuracy: 0.9691666666666666\n",
            "Weight: [-2.651977834251286, 1.2937684978404538] \n",
            "\n",
            "Epoch 16 loss: 0.0327777777777777\n",
            "Epoch 16 accuracy: 0.9672222222222222\n",
            "Weight: [-2.5997375701147893, 1.4296113479229644] \n",
            "\n",
            "Epoch 17 loss: 0.03305555555555548\n",
            "Epoch 17 accuracy: 0.9669444444444445\n",
            "Weight: [-2.62008312391099, 1.4364567328494824] \n",
            "\n",
            "Epoch 18 loss: 0.0313888888888888\n",
            "Epoch 18 accuracy: 0.9686111111111111\n",
            "Weight: [-2.6750301144712316, 1.299026356707218] \n",
            "\n",
            "Epoch 19 loss: 0.03111111111111102\n",
            "Epoch 19 accuracy: 0.9688888888888889\n",
            "Weight: [-2.657391287098776, 1.2905934457209463] \n",
            "\n",
            "Epoch 20 loss: 0.03194444444444436\n",
            "Epoch 20 accuracy: 0.9680555555555556\n",
            "Weight: [-2.652315341100206, 1.287253510062632] \n",
            "\n",
            "Best Weights: [-2.5936753850603522, 1.2528720248671057]\n",
            "Lowest error: 0.030833333333333244 \n",
            "\n",
            "****************** K-FOLD: 7 ******************\n",
            "Epoch 1 loss: 0.05055555555555559\n",
            "Epoch 1 accuracy: 0.9494444444444444\n",
            "Weight: [-1.8951297279151298, 0.8861169790880572] \n",
            "\n",
            "Epoch 2 loss: 0.03555555555555549\n",
            "Epoch 2 accuracy: 0.9644444444444444\n",
            "Weight: [-2.1729259202898885, 1.1779673322989954] \n",
            "\n",
            "Epoch 3 loss: 0.034444444444444375\n",
            "Epoch 3 accuracy: 0.9655555555555555\n",
            "Weight: [-2.3788126930580042, 1.2635106689942577] \n",
            "\n",
            "Epoch 4 loss: 0.03194444444444436\n",
            "Epoch 4 accuracy: 0.9680555555555556\n",
            "Weight: [-2.4759271025506937, 1.3179157413369922] \n",
            "\n",
            "Epoch 5 loss: 0.029999999999999916\n",
            "Epoch 5 accuracy: 0.97\n",
            "Weight: [-2.6452557744637275, 1.1952578318798313] \n",
            "\n",
            "Epoch 6 loss: 0.03027777777777769\n",
            "Epoch 6 accuracy: 0.9697222222222223\n",
            "Weight: [-2.719648557732666, 1.213197406007562] \n",
            "\n",
            "Epoch 7 loss: 0.02888888888888881\n",
            "Epoch 7 accuracy: 0.9711111111111111\n",
            "Weight: [-2.6858885647643715, 1.411830901824746] \n",
            "\n",
            "Epoch 8 loss: 0.028055555555555483\n",
            "Epoch 8 accuracy: 0.9719444444444445\n",
            "Weight: [-2.710192308733788, 1.424389538981352] \n",
            "\n",
            "Epoch 9 loss: 0.028055555555555483\n",
            "Epoch 9 accuracy: 0.9719444444444445\n",
            "Weight: [-2.7344960527032045, 1.4369481761379579] \n",
            "\n",
            "Epoch 10 loss: 0.027222222222222155\n",
            "Epoch 10 accuracy: 0.9727777777777777\n",
            "Weight: [-2.748569308984965, 1.4351316746039926] \n",
            "\n",
            "Epoch 11 loss: 0.02694444444444438\n",
            "Epoch 11 accuracy: 0.9730555555555556\n",
            "Weight: [-2.8110576510022978, 1.2604169110645358] \n",
            "\n",
            "Epoch 12 loss: 0.029444444444444363\n",
            "Epoch 12 accuracy: 0.9705555555555555\n",
            "Weight: [-2.775152521694503, 1.460586071096558] \n",
            "\n",
            "Epoch 13 loss: 0.028055555555555483\n",
            "Epoch 13 accuracy: 0.9719444444444445\n",
            "Weight: [-2.780301149879247, 1.4521164904205628] \n",
            "\n",
            "Epoch 14 loss: 0.02694444444444438\n",
            "Epoch 14 accuracy: 0.9730555555555556\n",
            "Weight: [-2.8427894918965797, 1.277401726881106] \n",
            "\n",
            "Epoch 15 loss: 0.028611111111111035\n",
            "Epoch 15 accuracy: 0.9713888888888889\n",
            "Weight: [-2.776442249867116, 1.4510646566726775] \n",
            "\n",
            "Epoch 16 loss: 0.02694444444444438\n",
            "Epoch 16 accuracy: 0.9730555555555556\n",
            "Weight: [-2.860300153324011, 1.2927874953038507] \n",
            "\n",
            "Epoch 17 loss: 0.02694444444444438\n",
            "Epoch 17 accuracy: 0.9730555555555556\n",
            "Weight: [-2.7746079458324595, 1.450038807984838] \n",
            "\n",
            "Epoch 18 loss: 0.02694444444444438\n",
            "Epoch 18 accuracy: 0.9730555555555556\n",
            "Weight: [-2.858465849289354, 1.2917616466160113] \n",
            "\n",
            "Epoch 19 loss: 0.02694444444444438\n",
            "Epoch 19 accuracy: 0.9730555555555556\n",
            "Weight: [-2.772773641797803, 1.4490129592969987] \n",
            "\n",
            "Epoch 20 loss: 0.02694444444444438\n",
            "Epoch 20 accuracy: 0.9730555555555556\n",
            "Weight: [-2.8566315452546975, 1.290735797928172] \n",
            "\n",
            "Best Weights: [-2.8110576510022978, 1.2604169110645358]\n",
            "Lowest error: 0.02694444444444438 \n",
            "\n",
            "****************** K-FOLD: 8 ******************\n",
            "Epoch 1 loss: 0.0572222222222223\n",
            "Epoch 1 accuracy: 0.9427777777777778\n",
            "Weight: [-1.9882821746367656, 1.0534595689401185] \n",
            "\n",
            "Epoch 2 loss: 0.03833333333333329\n",
            "Epoch 2 accuracy: 0.9616666666666667\n",
            "Weight: [-2.4334515425328376, 1.1370227449953425] \n",
            "\n",
            "Epoch 3 loss: 0.03194444444444436\n",
            "Epoch 3 accuracy: 0.9680555555555556\n",
            "Weight: [-2.529790256707035, 1.179399784864682] \n",
            "\n",
            "Epoch 4 loss: 0.03249999999999992\n",
            "Epoch 4 accuracy: 0.9675\n",
            "Weight: [-2.5311428980844504, 1.284726039488422] \n",
            "\n",
            "Epoch 5 loss: 0.03111111111111102\n",
            "Epoch 5 accuracy: 0.9688888888888889\n",
            "Weight: [-2.623880609246648, 1.2364484802450357] \n",
            "\n",
            "Epoch 6 loss: 0.030833333333333244\n",
            "Epoch 6 accuracy: 0.9691666666666666\n",
            "Weight: [-2.6681018409109636, 1.2381933799884244] \n",
            "\n",
            "Epoch 7 loss: 0.030833333333333244\n",
            "Epoch 7 accuracy: 0.9691666666666666\n",
            "Weight: [-2.6960078933369673, 1.2531870194445227] \n",
            "\n",
            "Epoch 8 loss: 0.030833333333333244\n",
            "Epoch 8 accuracy: 0.9691666666666666\n",
            "Weight: [-2.723913945762971, 1.268180658900621] \n",
            "\n",
            "Epoch 9 loss: 0.030833333333333244\n",
            "Epoch 9 accuracy: 0.9691666666666666\n",
            "Weight: [-2.7430282809301265, 1.2760379153729724] \n",
            "\n",
            "Epoch 10 loss: 0.030833333333333244\n",
            "Epoch 10 accuracy: 0.9691666666666666\n",
            "Weight: [-2.740372128875216, 1.3006993864359508] \n",
            "\n",
            "Epoch 11 loss: 0.029999999999999916\n",
            "Epoch 11 accuracy: 0.97\n",
            "Weight: [-2.738746073015189, 1.2736620454627456] \n",
            "\n",
            "Epoch 12 loss: 0.030833333333333244\n",
            "Epoch 12 accuracy: 0.9691666666666666\n",
            "Weight: [-2.7666521254411927, 1.288655684918844] \n",
            "\n",
            "Epoch 13 loss: 0.029999999999999916\n",
            "Epoch 13 accuracy: 0.97\n",
            "Weight: [-2.7699949179846906, 1.3153643616699557] \n",
            "\n",
            "Epoch 14 loss: 0.029999999999999916\n",
            "Epoch 14 accuracy: 0.97\n",
            "Weight: [-2.7683688621246634, 1.2883270206967505] \n",
            "\n",
            "Epoch 15 loss: 0.029999999999999916\n",
            "Epoch 15 accuracy: 0.97\n",
            "Weight: [-2.7717116546681613, 1.3150356974478623] \n",
            "\n",
            "Epoch 16 loss: 0.029999999999999916\n",
            "Epoch 16 accuracy: 0.97\n",
            "Weight: [-2.770085598808134, 1.287998356474657] \n",
            "\n",
            "Epoch 17 loss: 0.030555555555555468\n",
            "Epoch 17 accuracy: 0.9694444444444444\n",
            "Weight: [-2.767777671264498, 1.408957947496649] \n",
            "\n",
            "Epoch 18 loss: 0.02972222222222214\n",
            "Epoch 18 accuracy: 0.9702777777777778\n",
            "Weight: [-2.7865325471429685, 1.417808786396859] \n",
            "\n",
            "Epoch 19 loss: 0.028611111111111035\n",
            "Epoch 19 accuracy: 0.9713888888888889\n",
            "Weight: [-2.8048920333591996, 1.393149432684426] \n",
            "\n",
            "Epoch 20 loss: 0.03166666666666658\n",
            "Epoch 20 accuracy: 0.9683333333333334\n",
            "Weight: [-2.829907633555216, 1.4123632066284773] \n",
            "\n",
            "Best Weights: [-2.8048920333591996, 1.393149432684426]\n",
            "Lowest error: 0.028611111111111035 \n",
            "\n",
            "****************** K-FOLD: 9 ******************\n",
            "Epoch 1 loss: 0.054166666666666724\n",
            "Epoch 1 accuracy: 0.9458333333333333\n",
            "Weight: [-1.9512043868075297, 0.8234072077748342] \n",
            "\n",
            "Epoch 2 loss: 0.03916666666666663\n",
            "Epoch 2 accuracy: 0.9608333333333333\n",
            "Weight: [-2.3244008563797367, 1.235392801397481] \n",
            "\n",
            "Epoch 3 loss: 0.034166666666666595\n",
            "Epoch 3 accuracy: 0.9658333333333333\n",
            "Weight: [-2.57078556441684, 1.1147530936400287] \n",
            "\n",
            "Epoch 4 loss: 0.03194444444444436\n",
            "Epoch 4 accuracy: 0.9680555555555556\n",
            "Weight: [-2.676288747720418, 1.0517804213638933] \n",
            "\n",
            "Epoch 5 loss: 0.03111111111111102\n",
            "Epoch 5 accuracy: 0.9688888888888889\n",
            "Weight: [-2.6201829506515844, 1.348175007124487] \n",
            "\n",
            "Epoch 6 loss: 0.02972222222222214\n",
            "Epoch 6 accuracy: 0.9702777777777778\n",
            "Weight: [-2.6390936644936436, 1.354595785725526] \n",
            "\n",
            "Epoch 7 loss: 0.028611111111111035\n",
            "Epoch 7 accuracy: 0.9713888888888889\n",
            "Weight: [-2.664345221738329, 1.36616405008938] \n",
            "\n",
            "Epoch 8 loss: 0.030833333333333244\n",
            "Epoch 8 accuracy: 0.9691666666666666\n",
            "Weight: [-2.718794049122492, 1.3854476896382928] \n",
            "\n",
            "Epoch 9 loss: 0.027777777777777707\n",
            "Epoch 9 accuracy: 0.9722222222222222\n",
            "Weight: [-2.6936445099358513, 1.3803566270729843] \n",
            "\n",
            "Epoch 10 loss: 0.030833333333333244\n",
            "Epoch 10 accuracy: 0.9691666666666666\n",
            "Weight: [-2.7480933373200145, 1.3996402666218972] \n",
            "\n",
            "Epoch 11 loss: 0.027777777777777707\n",
            "Epoch 11 accuracy: 0.9722222222222222\n",
            "Weight: [-2.722943798133374, 1.3945492040565892] \n",
            "\n",
            "Epoch 12 loss: 0.030833333333333244\n",
            "Epoch 12 accuracy: 0.9691666666666666\n",
            "Weight: [-2.777392625517537, 1.413832843605502] \n",
            "\n",
            "Epoch 13 loss: 0.027777777777777707\n",
            "Epoch 13 accuracy: 0.9722222222222222\n",
            "Weight: [-2.7522430863308966, 1.408741781040194] \n",
            "\n",
            "Epoch 14 loss: 0.02888888888888881\n",
            "Epoch 14 accuracy: 0.9711111111111111\n",
            "Weight: [-2.774998748315479, 1.4081190826695549] \n",
            "\n",
            "Epoch 15 loss: 0.029166666666666587\n",
            "Epoch 15 accuracy: 0.9708333333333333\n",
            "Weight: [-2.8291223545967967, 1.2896363043133399] \n",
            "\n",
            "Epoch 16 loss: 0.029166666666666587\n",
            "Epoch 16 accuracy: 0.9708333333333333\n",
            "Weight: [-2.7997473064334595, 1.4300839336069056] \n",
            "\n",
            "Epoch 17 loss: 0.02888888888888881\n",
            "Epoch 17 accuracy: 0.9711111111111111\n",
            "Weight: [-2.822502968418042, 1.4294612352362663] \n",
            "\n",
            "Epoch 18 loss: 0.028055555555555483\n",
            "Epoch 18 accuracy: 0.9719444444444445\n",
            "Weight: [-2.8181914494312297, 1.4289975994830497] \n",
            "\n",
            "Epoch 19 loss: 0.028055555555555483\n",
            "Epoch 19 accuracy: 0.9719444444444445\n",
            "Weight: [-2.8138799304444175, 1.428533963729833] \n",
            "\n",
            "Epoch 20 loss: 0.029166666666666587\n",
            "Epoch 20 accuracy: 0.9708333333333333\n",
            "Weight: [-2.8680035367257353, 1.310051185373618] \n",
            "\n",
            "Best Weights: [-2.6936445099358513, 1.3803566270729843]\n",
            "Lowest error: 0.027777777777777707 \n",
            "\n",
            "****************** K-FOLD: 10 ******************\n",
            "Epoch 1 loss: 0.060277777777777874\n",
            "Epoch 1 accuracy: 0.9397222222222222\n",
            "Weight: [-2.0216493684434913, 0.9787513069875016] \n",
            "\n",
            "Epoch 2 loss: 0.03722222222222217\n",
            "Epoch 2 accuracy: 0.9627777777777777\n",
            "Weight: [-2.2779874075454303, 1.2108787320843082] \n",
            "\n",
            "Epoch 3 loss: 0.03749999999999995\n",
            "Epoch 3 accuracy: 0.9625\n",
            "Weight: [-2.4436761284936104, 1.3118752937223566] \n",
            "\n",
            "Epoch 4 loss: 0.03555555555555549\n",
            "Epoch 4 accuracy: 0.9644444444444444\n",
            "Weight: [-2.562529851040067, 1.3439526265879242] \n",
            "\n",
            "Epoch 5 loss: 0.033611111111111036\n",
            "Epoch 5 accuracy: 0.9663888888888889\n",
            "Weight: [-2.6237692944553803, 1.3745383336010322] \n",
            "\n",
            "Epoch 6 loss: 0.033611111111111036\n",
            "Epoch 6 accuracy: 0.9663888888888889\n",
            "Weight: [-2.6850087378706933, 1.4051240406141396] \n",
            "\n",
            "Epoch 7 loss: 0.0327777777777777\n",
            "Epoch 7 accuracy: 0.9672222222222222\n",
            "Weight: [-2.696838220817065, 1.419244090100279] \n",
            "\n",
            "Epoch 8 loss: 0.0327777777777777\n",
            "Epoch 8 accuracy: 0.9672222222222222\n",
            "Weight: [-2.6863711313299055, 1.431860128822848] \n",
            "\n",
            "Epoch 9 loss: 0.03305555555555548\n",
            "Epoch 9 accuracy: 0.9669444444444445\n",
            "Weight: [-2.761686538952152, 1.4079247639646941] \n",
            "\n",
            "Epoch 10 loss: 0.03111111111111102\n",
            "Epoch 10 accuracy: 0.9688888888888889\n",
            "Weight: [-2.7520112531827023, 1.3999431494554249] \n",
            "\n",
            "Epoch 11 loss: 0.03111111111111102\n",
            "Epoch 11 accuracy: 0.9688888888888889\n",
            "Weight: [-2.664812210533555, 1.4521425149059823] \n",
            "\n",
            "Epoch 12 loss: 0.034722222222222154\n",
            "Epoch 12 accuracy: 0.9652777777777778\n",
            "Weight: [-2.7959848893917196, 1.4799666086977583] \n",
            "\n",
            "Epoch 13 loss: 0.0313888888888888\n",
            "Epoch 13 accuracy: 0.9686111111111111\n",
            "Weight: [-2.7406383136367958, 1.4888397757489777] \n",
            "\n",
            "Epoch 14 loss: 0.0327777777777777\n",
            "Epoch 14 accuracy: 0.9672222222222222\n",
            "Weight: [-2.7867184706267443, 1.4995998249016795] \n",
            "\n",
            "Epoch 15 loss: 0.03166666666666658\n",
            "Epoch 15 accuracy: 0.9683333333333334\n",
            "Weight: [-2.7950244016517685, 1.504166031391761] \n",
            "\n",
            "Epoch 16 loss: 0.03166666666666658\n",
            "Epoch 16 accuracy: 0.9683333333333334\n",
            "Weight: [-2.801339142000322, 1.5071596624933459] \n",
            "\n",
            "Epoch 17 loss: 0.03166666666666658\n",
            "Epoch 17 accuracy: 0.9683333333333334\n",
            "Weight: [-2.807653882348876, 1.5101532935949307] \n",
            "\n",
            "Epoch 18 loss: 0.03166666666666658\n",
            "Epoch 18 accuracy: 0.9683333333333334\n",
            "Weight: [-2.8139686226974296, 1.5131469246965155] \n",
            "\n",
            "Epoch 19 loss: 0.03166666666666658\n",
            "Epoch 19 accuracy: 0.9683333333333334\n",
            "Weight: [-2.8202833630459834, 1.5161405557981003] \n",
            "\n",
            "Epoch 20 loss: 0.030555555555555468\n",
            "Epoch 20 accuracy: 0.9694444444444444\n",
            "Weight: [-2.7904605845302712, 1.4826148896032638] \n",
            "\n",
            "Best Weights: [-2.7904605845302712, 1.4826148896032638]\n",
            "Lowest error: 0.030555555555555468 \n",
            "\n",
            "Average Validation Loss: 0.076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred=0\n",
        "classification_error=0\n",
        "predA = []\n",
        "for j in range(len(X_test)):\n",
        "  row_j = X_test.iloc[j]\n",
        "  target = y_test.iloc[j]\n",
        "  weighted_sum = np.dot(row_j, save_weights[4])+1\n",
        "  prediction = perceptron_activation(weighted_sum)\n",
        "  predA.append(prediction)\n",
        "  if(prediction==target):\n",
        "    correct_pred+=1\n",
        "  classification_error += (1/len(data))*(abs(1/2*(y_test-prediction)))\n",
        "\n",
        "accuracy = correct_pred/len(X_test)\n",
        "print(\"Accuracy on test set is\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rPAbcZ7qXZd",
        "outputId": "4dea5c64-68b6-4dea-ac62-33280bc441fa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set is 0.982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "29YdzHaH9iik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}