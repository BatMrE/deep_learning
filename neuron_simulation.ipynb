{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D154hMPAOtL2"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kf = KFold(n_splits=10)\n",
        "# mse_adaline_bgd = []\n",
        "# mse_adaline_sgd = []\n",
        "# mse_sigmoid_bgd = []\n",
        "# mse_sigmoid_sgd = []\n",
        "\n",
        "# for train_index, test_index in kf.split(x):\n",
        "#     X_train, X_test = x[train_index], x[test_index]\n",
        "#     y_train, y_test = y_true[train_index], y_true[test_index]\n",
        "\n",
        "#     X_train_poly = np.column_stack([X_train, X_train**2, X_train**3])\n",
        "#     X_test_poly = np.column_stack([X_test, X_test**2, X_test**3])\n",
        "\n",
        "#     # Adaline with BGD\n",
        "#     adaline_bgd = AdalineNeuron()\n",
        "#     adaline_bgd.fit(X_train_poly, y_train)\n",
        "#     y_pred = adaline_bgd.predict(X_test_poly)\n",
        "#     mse_adaline_bgd.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "#     # Adaline with SGD\n",
        "#     adaline_sgd = AdalineNeuron()\n",
        "#     adaline_sgd.fit(X_train_poly, y_train)\n",
        "#     y_pred = adaline_sgd.predict(X_test_poly)\n",
        "#     mse_adaline_sgd.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "#     # Sigmoid with BGD\n",
        "#     sigmoid_bgd = SigmoidNeuron()\n",
        "#     sigmoid_bgd.fit(X_train_poly, y_train)\n",
        "#     y_pred = sigmoid_bgd.predict(X_test_poly)\n",
        "#     mse_sigmoid_bgd.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "#     # Sigmoid with SGD\n",
        "#     sigmoid_sgd = SigmoidNeuron()\n",
        "#     sigmoid_sgd.fit(X_train_poly, y_train)\n",
        "#     y_pred = sigmoid_sgd.predict(X_test_poly)\n",
        "#     mse_sigmoid_sgd.append(mean_squared_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "xGsJwOyNPZAP",
        "outputId": "657fab59-b9c4-4d26-8cda-2a66e8b781e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-68034b52cbe4>:25: RuntimeWarning: invalid value encountered in add\n",
            "  self.weights += self.learning_rate * gradient\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a4946ee39e5c>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0madaline_bgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaline_bgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_poly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmse_adaline_bgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Adaline with SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \"\"\"\n\u001b[0;32m--> 442\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Mean Squared Error (Adaline BGD):\", np.mean(mse_adaline_bgd))\n",
        "# print(\"Mean Squared Error (Adaline SGD):\", np.mean(mse_adaline_sgd))\n",
        "# print(\"Mean Squared Error (Sigmoid BGD):\", np.mean(mse_sigmoid_bgd))\n",
        "# print(\"Mean Squared Error (Sigmoid SGD):\", np.mean(mse_sigmoid_sgd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjDQREBKPe5L",
        "outputId": "fbfe18eb-9cb3-4469-faa2-39c2040f2735"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Adaline BGD): nan\n",
            "Mean Squared Error (Adaline SGD): nan\n",
            "Mean Squared Error (Sigmoid BGD): nan\n",
            "Mean Squared Error (Sigmoid SGD): nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Generate Synthetic Data\n",
        "np.random.seed(42)  # for reproducibility\n",
        "x = np.random.normal(0, 1, size=5000)\n",
        "eps = np.random.normal(0, 0.25, size=5000)\n",
        "y_true = -1 + 0.5*x - 2*x**2 + 0.3*x**3 + eps\n",
        "\n",
        "# Step 2: Implement Adaline and Sigmoid Neuron\n",
        "\n",
        "# Adaline Neuron\n",
        "class AdalineNeuron:\n",
        "    def __init__(self, learning_rate=0.01, max_iter=1000, tol=1e-4, clip_gradient=1e-3):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.clip_gradient = clip_gradient\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.random.randn(X.shape[1])\n",
        "        for _ in range(self.max_iter):\n",
        "            errors = y - self.predict(X)\n",
        "            gradient = np.dot(X.T, errors)\n",
        "            gradient = np.clip(gradient, -self.clip_gradient, self.clip_gradient)\n",
        "            self.weights += self.learning_rate * gradient\n",
        "            if np.all(np.abs(errors) < self.tol):\n",
        "                break\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights)\n",
        "\n",
        "# Sigmoid Neuron\n",
        "class SigmoidNeuron:\n",
        "    def __init__(self, learning_rate=0.01, max_iter=1000, tol=1e-4, clip_gradient=1e-3):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.clip_gradient = clip_gradient\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.random.randn(X.shape[1])\n",
        "        for _ in range(self.max_iter):\n",
        "            errors = y - self.predict(X)\n",
        "            gradient = np.dot(X.T, errors * self.sigmoid(self.predict(X)) * (1 - self.sigmoid(self.predict(X))))\n",
        "            gradient = np.clip(gradient, -self.clip_gradient, self.clip_gradient)\n",
        "            self.weights += self.learning_rate * gradient\n",
        "            if np.all(np.abs(errors) < self.tol):\n",
        "                break\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights)\n",
        "\n",
        "# Step 3: Cross-Validation\n",
        "kf = KFold(n_splits=10)\n",
        "mse_adaline_bgd = []\n",
        "mse_adaline_sgd = []\n",
        "mse_sigmoid_bgd = []\n",
        "mse_sigmoid_sgd = []\n",
        "\n",
        "for train_index, test_index in kf.split(x):\n",
        "    X_train, X_test = x[train_index], x[test_index]\n",
        "    y_train, y_test = y_true[train_index], y_true[test_index]\n",
        "\n",
        "    X_train_poly = np.column_stack([X_train, X_train**2, X_train**3])\n",
        "    X_test_poly = np.column_stack([X_test, X_test**2, X_test**3])\n",
        "\n",
        "    # Adaline with BGD\n",
        "    adaline_bgd = AdalineNeuron()\n",
        "    adaline_bgd.fit(X_train_poly, y_train)\n",
        "    y_pred = adaline_bgd.predict(X_test_poly)\n",
        "    mse_adaline_bgd.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    # Adaline with SGD\n",
        "    adaline_sgd = AdalineNeuron()\n",
        "    adaline_sgd.fit(X_train_poly, y_train)\n",
        "    y_pred = adaline_sgd.predict(X_test_poly)\n",
        "    mse_adaline_sgd.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    # Sigmoid with BGD\n",
        "    sigmoid_bgd = SigmoidNeuron()\n",
        "    sigmoid_bgd.fit(X_train_poly, y_train)\n",
        "    y_pred = sigmoid_bgd.predict(X_test_poly)\n",
        "    mse_sigmoid_bgd.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    # Sigmoid with SGD\n",
        "    sigmoid_sgd = SigmoidNeuron()\n",
        "    sigmoid_sgd.fit(X_train_poly, y_train)\n",
        "    y_pred = sigmoid_sgd.predict(X_test_poly)\n",
        "    mse_sigmoid_sgd.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Step 4: Evaluate and Compare\n",
        "print(\"Mean Squared Error (Adaline BGD):\", np.mean(mse_adaline_bgd))\n",
        "print(\"Mean Squared Error (Adaline SGD):\", np.mean(mse_adaline_sgd))\n",
        "print(\"Mean Squared Error (Sigmoid BGD):\", np.mean(mse_sigmoid_bgd))\n",
        "print(\"Mean Squared Error (Sigmoid SGD):\", np.mean(mse_sigmoid_sgd))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KuFlWeifeR2",
        "outputId": "c9567b6d-ad93-40ba-936b-8b8a286f61c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Adaline BGD): 37.457211696137094\n",
            "Mean Squared Error (Adaline SGD): 26.27182332343039\n",
            "Mean Squared Error (Sigmoid BGD): 45.99841615249595\n",
            "Mean Squared Error (Sigmoid SGD): 40.71439462068595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Generate Synthetic Data\n",
        "np.random.seed(42)  # for reproducibility\n",
        "\n",
        "# Generate random linearly separable data\n",
        "class_minus1 = np.random.rand(2500, 2) * 10 - 5  # Class -1\n",
        "class_plus1 = np.random.rand(2500, 2) * 10 - 5  # Class +1\n",
        "\n",
        "# Step 2: Implement Perceptron Learning Algorithm\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, max_iter=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        for _ in range(self.max_iter):\n",
        "            for i in range(X.shape[0]):\n",
        "                if y[i] * np.dot(X[i], self.weights) <= 0:\n",
        "                    self.weights += self.learning_rate * y[i] * X[i]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.sign(np.dot(X, self.weights))\n",
        "\n",
        "# Step 3: Cross-Validation\n",
        "X = np.vstack((class_minus1, class_plus1))\n",
        "y = np.hstack((np.full(2500, -1), np.full(2500, 1)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perceptron with different learning rates and training set sizes\n",
        "learning_rates = [0.01, 0.1, 1]\n",
        "training_sizes = [0.5, 0.7, 0.9]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for ts in training_sizes:\n",
        "        X_train_partial, _, y_train_partial, _ = train_test_split(X_train, y_train, train_size=ts, random_state=42)\n",
        "        perceptron = Perceptron(learning_rate=lr)\n",
        "        perceptron.fit(X_train_partial, y_train_partial)\n",
        "        y_pred = perceptron.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Perceptron with LR={lr}, Training Size={ts}: Accuracy={accuracy}\")\n",
        "\n",
        "# Step 4: Choose one variant and implement\n",
        "# Let's choose the Pocket algorithm as the variant\n",
        "class PocketPerceptron(Perceptron):\n",
        "    def __init__(self, learning_rate=0.01, max_iter=1000):\n",
        "        super().__init__(learning_rate, max_iter)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.best_weights = np.zeros(X.shape[1])\n",
        "        best_accuracy = 0\n",
        "        for _ in range(self.max_iter):\n",
        "            for i in range(X.shape[0]):\n",
        "                if y[i] * np.dot(X[i], self.weights) <= 0:\n",
        "                    self.weights += self.learning_rate * y[i] * X[i]\n",
        "                    y_pred = self.predict(X)\n",
        "                    accuracy = accuracy_score(y, y_pred)\n",
        "                    if accuracy > best_accuracy:\n",
        "                        best_accuracy = accuracy\n",
        "                        self.best_weights = np.copy(self.weights)\n",
        "        self.weights = self.best_weights\n",
        "\n",
        "# Repeat cross-validation with Pocket Perceptron\n",
        "pocket_perceptron = PocketPerceptron()\n",
        "pocket_perceptron.fit(X_train, y_train)\n",
        "y_pred_pocket = pocket_perceptron.predict(X_test)\n",
        "accuracy_pocket = accuracy_score(y_test, y_pred_pocket)\n",
        "print(f\"Pocket Perceptron: Accuracy={accuracy_pocket}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXqkFBAriBe6",
        "outputId": "0f78bebc-adec-4b4f-aa87-ca8faf53505f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron with LR=0.01, Training Size=0.5: Accuracy=0.525\n",
            "Perceptron with LR=0.01, Training Size=0.7: Accuracy=0.519\n",
            "Perceptron with LR=0.01, Training Size=0.9: Accuracy=0.52\n",
            "Perceptron with LR=0.1, Training Size=0.5: Accuracy=0.525\n",
            "Perceptron with LR=0.1, Training Size=0.7: Accuracy=0.519\n",
            "Perceptron with LR=0.1, Training Size=0.9: Accuracy=0.52\n",
            "Perceptron with LR=1, Training Size=0.5: Accuracy=0.525\n",
            "Perceptron with LR=1, Training Size=0.7: Accuracy=0.519\n",
            "Perceptron with LR=1, Training Size=0.9: Accuracy=0.52\n",
            "Pocket Perceptron: Accuracy=0.513\n"
          ]
        }
      ]
    }
  ]
}